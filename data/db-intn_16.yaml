- en: Chapter 13\. Distributed Transactions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第13章\. 分布式事务
- en: To maintain order in a distributed system, we have to guarantee at least some
    consistency. In [“Consistency Models”](ch11.html#consistency_models), we talked
    about single-object, single-operation consistency models that help us to reason
    about the individual operations. However, in databases we often need to execute
    *multiple* operations atomically.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 要在分布式系统中保持顺序，我们必须至少保证一定的一致性。在[“一致性模型”](ch11.html#consistency_models)中，我们讨论了单对象、单操作的一致性模型，这些模型帮助我们推理关于单个操作的情况。然而，在数据库中，我们经常需要原子地执行*多个*操作。
- en: 'Atomic operations are explained in terms of state transitions: the database
    was in state `A` before a particular transaction was started; by the time it finished,
    the state went from `A` to `B`. In operation terms, this is simple to understand,
    since transactions have no predetermined attached state. Instead, they apply operations
    to data records starting at *some* point in time. This gives us some flexibility
    in terms of scheduling and execution: transactions can be reordered and even retried.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 原子操作通常通过状态转换来解释：特定事务开始前，数据库处于状态`A`；事务结束时，状态从`A`变为`B`。操作方面，这很容易理解，因为事务没有预先确定的附加状态。相反，它们从某个时间点开始对数据记录应用操作。这为我们在调度和执行方面提供了一些灵活性：事务可以重新排序甚至重试。
- en: 'The main focus of transaction processing is to determine permissible *histories*,
    to model and represent possible interleaving execution scenarios. History, in
    this case, represents a dependency graph: which transactions have been executed
    prior to execution of the current transaction. History is said to be *serializable*
    if it is equivalent (i.e., has the same dependency graph) to *some* history that
    executes these transactions sequentially. You can review concepts of histories,
    their equivalence, serializability, and other concepts in [“Serializability”](ch05.html#serializability).
    Generally, this chapter is a distributed systems counterpart of [Chapter 5](ch05.html#transaction_processing),
    where we discussed node-local transaction processing.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 事务处理的主要焦点是确定可接受的*历史*，以建模和表示可能的交错执行场景。在这种情况下，历史代表一个依赖图：在当前事务执行之前执行了哪些事务。如果历史可序列化，那么它相当于某些以顺序执行这些事务的历史（即具有相同的依赖图）。您可以在[“可序列化性”](ch05.html#serializability)中查阅关于历史、它们的等价性、可序列化性和其他概念的概念。一般来说，这一章是[第5章](ch05.html#transaction_processing)的分布式系统对应章节，我们在其中讨论了节点本地事务处理。
- en: Single-partition transactions involve the pessimistic (lock-based or tracking)
    or optimistic (try and validate) concurrency control schemes that we discussed
    in [Chapter 5](ch05.html#transaction_processing), but neither one of these approaches
    solves the problem of multipartition transactions, which require coordination
    between different servers, distributed commit, and rollback protocols.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 单分区事务涉及我们在[第5章](ch05.html#transaction_processing)中讨论过的悲观（基于锁或跟踪）或乐观（尝试和验证）并发控制方案，但这两种方法都不能解决多分区事务的问题，这些事务需要在不同服务器之间进行协调，分布式提交和回滚协议。
- en: 'Generally speaking, when transferring money from one account to another, you’d
    like to both credit the first account and debit the second one *simultaneously*.
    However, if we break down the transaction into individual steps, even debiting
    or crediting doesn’t look atomic at first sight: we need to read the old balance,
    add or subtract the required amount, and save this result. Each one of these substeps
    involves several operations: the node receives a request, parses it, locates the
    data on disk, makes a write and, finally, acknowledges it. Even this is a rather
    high-level view: to execute a simple write, we have to perform hundreds of small
    steps.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，当从一个帐户转账到另一个帐户时，您希望同时向第一个帐户存款并从第二个帐户取款。然而，即使我们将交易分解为单独的步骤，即使是借方或贷方看起来也不是原子的：我们需要读取旧余额，添加或减去所需金额，并保存结果。这些子步骤中的每一个都涉及多个操作：节点接收请求，解析请求，定位磁盘上的数据，进行写操作，最后确认操作。即使这已经是一个相对高层次的视角：要执行一个简单的写操作，我们必须执行数百个小步骤。
- en: This means that we have to first *execute* the transaction and only then make
    its results *visible*. But let’s first define what transactions are. A *transaction*
    is a set of operations, an atomic unit of execution. Transaction atomicity implies
    that all its results become visible or none of them do. For example, if we modify
    several rows, or even tables in a single transaction, either all or none of the
    modifications will be applied.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们必须首先*执行*事务，然后才能使其结果*可见*。但让我们首先定义一下什么是事务。*事务*是一组操作，是一个原子执行单元。事务的原子性意味着其所有结果要么全部变为可见，要么全部不可见。例如，如果我们在一个事务中修改了几行，甚至是几个表，这些修改要么全部应用，要么全部不应用。
- en: To ensure atomicity, transactions should be *recoverable*. In other words, if
    the transaction cannot complete, is aborted, or times out, its results have to
    be rolled back completely. A nonrecoverable, partially executed transaction can
    leave the database in an inconsistent state. In summary, in case of unsuccessful
    transaction execution, the database state has to be reverted to its previous state,
    as if this transaction was never tried in the first place.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保原子性，事务应该是*可恢复*的。换句话说，如果事务无法完成、中止或超时，其结果必须完全回滚。一个不可恢复的部分执行的事务可能会使数据库处于不一致状态。总结来说，如果事务执行失败，数据库状态必须恢复到其先前的状态，就好像这个事务从未尝试过一样。
- en: 'Another important aspect is network partitions and node failures: nodes in
    the system fail and recover independently, but their states have to remain consistent.
    This means that the atomicity requirement holds not only for the local operations,
    but also for operations executed on other nodes: changes have to be durably propagated
    to all of the nodes involved in the transaction or none of them [[LAMPSON79]](app01.html#LAMPSON79).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要方面是网络分区和节点故障：系统中的节点会独立地发生故障和恢复，但它们的状态必须保持一致。这意味着原子性要求不仅适用于本地操作，还适用于在其他节点执行的操作：更改必须耐久地传播到涉及到的所有节点或者完全不传播[[LAMPSON79]](app01.html#LAMPSON79)。
- en: Making Operations Appear Atomic
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使操作看起来是原子的
- en: 'To make multiple operations appear atomic, especially if some of them are remote,
    we need to use a class of algorithms called *atomic commitment*. Atomic commitment
    doesn’t allow disagreements between the participants: a transaction *will not*
    commit if even one of the participants votes against it. At the same time, this
    means that *failed* processes have to reach the same conclusion as the rest of
    the cohort. Another important implication of this fact is that atomic commitment
    algorithms do not work in the presence of Byzantine failures: when the process
    lies about its state or decides on an arbitrary value, since it contradicts unanimity
    [[HADZILACOS05]](app01.html#HADZILACOS05).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使多个操作看起来是原子的，特别是如果其中一些操作是远程的，我们需要使用一类称为*原子提交*的算法。原子提交不允许参与者之间产生分歧：即使一个参与者反对，事务也*不会*提交。与此同时，这意味着*失败*的进程必须与其他同伴达成相同的结论。这个事实的另一个重要含义是，在存在拜占庭失败时，原子提交算法无法工作：当进程关于其状态撒谎或者决定一个任意值时，因为它违反了一致性[[HADZILACOS05]](app01.html#HADZILACOS05)。
- en: 'The problem that atomic commitment is trying to solve is reaching an agreement
    on whether or not to execute the proposed transaction. Cohorts cannot choose,
    influence, or change the proposed transaction or propose any alternative: they
    can only give their vote on whether or not they are willing to execute it [[ROBINSON08]](app01.html#ROBINSON08).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 原子提交试图解决的问题是就是否执行所提出的事务达成一致意见。同伴不能选择、影响或更改提出的事务，也不能提出任何替代方案：他们只能就是否愿意执行它发表投票[[ROBINSON08]](app01.html#ROBINSON08)。
- en: 'Atomic commitment algorithms do not set strict requirements for the semantics
    of transaction *prepare*, *commit*, or *rollback* operations. Database implementers
    have to decide on:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 原子提交算法不对事务*准备*、*提交*或*回滚*操作的语义设置严格的要求。数据库实施者必须决定：
- en: When the data is considered ready to commit, and they’re just a pointer swap
    away from making the changes public.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当数据被认为准备提交时，它们只需进行指针交换即可使更改公开。
- en: How to perform the commit itself to make transaction results visible in the
    shortest timeframe possible.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何执行提交本身以使事务结果在最短时间内可见。
- en: How to roll back the changes made by the transaction if the algorithm decides
    not to commit.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果算法决定不提交，如何回滚事务所做的更改。
- en: We discussed node-local implementations of these processes in [Chapter 5](ch05.html#transaction_processing).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第5章](ch05.html#transaction_processing)中讨论了这些过程的节点本地实现。
- en: Many distributed systems use atomic commitment algorithms—for example, MySQL
    (for [distributed transactions](https://databass.dev/links/5)) and Kafka (for
    producer and consumer interaction [[MEHTA17]](app01.html#MEHTA17)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 许多分布式系统使用原子提交算法，例如，MySQL（用于[分布式事务](https://databass.dev/links/5)）和Kafka（用于生产者和消费者交互[[MEHTA17]](app01.html#MEHTA17)）。
- en: In databases, distributed transactions are executed by the component commonly
    known as a *transaction manager*. The transaction manager is a subsystem responsible
    for scheduling, coordinating, executing, and tracking transactions. In a distributed
    environment, the transaction manager is responsible for ensuring that node-local
    visibility guarantees are consistent with the visibility prescribed by distributed
    atomic operations. In other words, transactions commit in all partitions, and
    for all replicas.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据库中，分布式事务由通常称为*事务管理器*的组件执行。事务管理器是一个子系统，负责调度、协调、执行和跟踪事务。在分布式环境中，事务管理器负责确保节点本地可见性保证与分布式原子操作规定的可见性一致。换句话说，事务在所有分区和所有副本上都提交。
- en: 'We will discuss two atomic commitment algorithms: two-phase commit, which solves
    a commitment problem, but doesn’t allow for failures of the coordinator process;
    and three-phase commit [[SKEEN83]](app01.html#SKEEN83), which solves a *nonblocking
    atomic commitment* problem,^([1](ch13.html#idm46466885552408)) and allows participants
    proceed even in case of coordinator failures [[BABAOGLU93]](app01.html#BABAOGLU93).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论两种原子提交算法：解决承诺问题的两阶段提交，但不允许协调者进程失败；以及解决*非阻塞原子提交*问题的三阶段提交[[SKEEN83]](app01.html#SKEEN83)，并允许参与者在协调者失败的情况下继续[[BABAOGLU93]](app01.html#BABAOGLU93)。
- en: Two-Phase Commit
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 两阶段提交
- en: Let’s start with the most straightforward protocol for a distributed commit
    that allows multipartition *atomic* updates. (For more information on partitioning,
    you can refer to [“Database Partitioning”](#database_partitioning).) *Two-phase
    commit* (2PC) is usually discussed in the context of database transactions. 2PC
    executes in two phases. During the first phase, the decided value is distributed,
    and votes are collected. During the second phase, nodes just flip the switch,
    making the results of the first phase visible.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个最简单的协议开始，用于允许多分区*原子*更新的分布式提交（有关分区更多信息，请参阅[“数据库分区”](#database_partitioning)）。*两阶段提交*（2PC）通常在数据库事务的上下文中讨论。2PC分为两个阶段执行。在第一阶段，决定的值被分发，并收集投票。在第二阶段，节点只需切换开关，使第一阶段的结果可见。
- en: 2PC assumes the presence of a *leader* (or *coordinator*) that holds the state,
    collects votes, and is a primary point of reference for the agreement round. The
    rest of the nodes are called *cohorts*. Cohorts, in this case, are usually partitions
    that operate over disjoint datasets, against which transactions are performed.
    The coordinator and every cohort keep local operation logs for each executed step.
    Participants vote to accept or reject some *value*, proposed by the coordinator.
    Most often, this value is an identifier of the distributed transaction that has
    to be executed, but 2PC can be used in other contexts as well.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 2PC假设存在一个*领导者*（或*协调者*），该领导者持有状态，收集投票，并是协议循环的主要参考点。其余的节点称为*同僚*。在这种情况下，同僚通常是操作于不相交数据集的分区，反对执行事务。协调者和每个同僚为每个执行步骤保留本地操作日志。参与者投票接受或拒绝由协调者提出的某个*值*。最常见的情况是，这个值是要执行的分布式事务的标识符，但2PC也可以用于其他情境。
- en: The coordinator can be a node that received a request to execute the transaction,
    or it can be picked at random, using a leader-election algorithm, assigned manually,
    or even fixed throughout the lifetime of the system. The protocol does not place
    restrictions on the coordinator role, and the role can be transferred to another
    participant for reliability or performance.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 协调者可以是收到执行事务请求的节点，也可以是随机选取的节点，使用领导选举算法、手动分配，甚至在系统的整个生命周期内固定使用的节点。协议不对协调者角色施加限制，并且角色可以为了可靠性或性能而转移到另一个参与者。
- en: 'As the name suggests, a two-phase commit is executed in two steps:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 顾名思义，两阶段提交分为两个步骤执行：
- en: Prepare
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 准备
- en: The coordinator notifies cohorts about the new transaction by sending a `Propose`
    message. Cohorts make a decision on whether or not they can commit the part of
    the transaction that applies to them. If a cohort decides that it can commit,
    it notifies the coordinator about the positive vote. Otherwise, it responds to
    the coordinator, asking it to abort the transaction. All decisions taken by cohorts
    are persisted in the coordinator log, and each cohort keeps a copy of its decision
    locally.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 协调者通过发送`Propose`消息通知成员有新的事务。成员决定他们是否可以提交适用于他们的事务部分。如果成员决定可以提交，它通知协调者有积极的投票。否则，它回复协调者，要求中止事务。成员做出的所有决策都记录在协调者日志中，并且每个成员在本地保存决策的副本。
- en: Commit/abort
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 提交/中止
- en: Operations within a transaction can change state across different partitions
    (each represented by a cohort). If even one of the cohorts votes to abort the
    transaction, the coordinator sends the `Abort` message to all of them. Only if
    all cohorts have voted positively does the coordinator send them a final `Commit`
    message.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 事务中的操作可以跨不同分区（每个由成员代表）。如果其中一个成员投票中止事务，协调者将向所有成员发送`Abort`消息。只有所有成员都投票赞成时，协调者才会向它们发送最终的`Commit`消息。
- en: This process is shown in [Figure 13-1](#two_phase_commit_1).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这一过程显示在[图 13-1](#two_phase_commit_1)中。
- en: During the *prepare* phase, the coordinator distributes the proposed value and
    collects votes from the participants on whether or not this proposed value should
    be committed. Cohorts may choose to reject the coordinator’s proposal if, for
    example, another conflicting transaction has already committed a different value.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在*准备*阶段，协调者分发提议值，并且收集来自参与者的投票，确定是否应该提交这个提议值。例如，如果另一个冲突的事务已经提交了不同的值，成员可以选择拒绝协调者的提议。
- en: '![dbin 1301](assets/dbin_1301.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![dbin 1301](assets/dbin_1301.png)'
- en: Figure 13-1\. Two-phase commit protocol. During the first phase, cohorts are
    notified about the new transaction. During the second phase, the transaction is
    committed or aborted.
  id: totrans-32
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 13-1\. 两阶段提交协议。在第一阶段，各个成员被通知有新的事务。在第二阶段，事务被提交或者终止。
- en: After the coordinator has collected the votes, it can make a decision on whether
    to *commit* the transaction or *abort* it. If all cohorts have voted positively,
    it decides to commit and notifies them by sending a `Commit` message. Otherwise,
    the coordinator sends an `Abort` message to all cohorts and the transaction gets
    rolled back. In other words, if one node rejects the proposal, the whole round
    is aborted.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当协调者收集到所有投票后，它可以决定是*提交*事务还是*中止*事务。如果所有的成员都投票赞成，它决定提交并且通过发送`Commit`消息通知他们。否则，协调者向所有成员发送一个`Abort`消息，事务被回滚。换句话说，如果一个节点拒绝了提议，整个轮次就被中止。
- en: During each step the coordinator and cohorts have to write the results of each
    operation to durable storage to be able to reconstruct the state and recover in
    case of local failures, and be able to forward and replay results for other participants.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一步中，协调者和成员必须将每个操作的结果写入持久存储，以便能够重建状态并在本地故障时恢复，并且能够将结果转发和重放给其他参与者。
- en: In the context of database systems, each 2PC round is usually responsible for
    a single transaction. During the *prepare* phase, transaction contents (operations,
    identifiers, and other metadata) are transferred from the coordinator to the cohorts.
    The transaction is executed by the cohorts locally and is left in a *partially
    committed* state (sometimes called *precommitted*), making it ready for the coordinator
    to finalize execution during the next phase by either committing or aborting it.
    By the time the transaction commits, its contents are already stored durably on
    all other nodes [[BERNSTEIN09]](app01.html#BERNSTEIN09).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据库系统的背景下，每个两阶段提交的轮次通常负责一个单独的事务。在*准备*阶段，事务内容（操作、标识符和其他元数据）从协调者传输到各个成员。事务由各个成员本地执行，并且保持在*部分提交*状态（有时称为*预提交*），使得协调者可以在下一个阶段通过提交或者中止来最终执行。在事务提交时，其内容已经持久地存储在所有其他节点上
    [[BERNSTEIN09]](app01.html#BERNSTEIN09)。
- en: Cohort Failures in 2PC
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 两阶段提交中的成员失败
- en: 'Let’s consider several failure scenarios. For example, as [Figure 13-2](#two_phase_commit_failure)
    shows, if one of the cohorts fails during the *propose* phase, the coordinator
    cannot proceed with a commit, since it requires all votes to be positive. If one
    of the cohorts is unavailable, the coordinator will abort the transaction. This
    requirement has a negative impact on availability: failure of a single node can
    prevent transactions from happening. Some systems, for example, Spanner (see [“Distributed
    Transactions with Spanner”](#spanner)), perform 2PC over Paxos groups rather than
    individual nodes to improve protocol availability.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑几种失败场景。例如，如图[13-2](#two_phase_commit_failure)所示，如果其中一个队伍在*提议*阶段失败，协调者无法进行提交，因为它需要所有的投票都是积极的。如果其中一个队伍不可用，协调者将中止事务。这一要求对可用性有负面影响：单个节点的故障可能会阻止事务的发生。例如，一些系统，例如Spanner（参见[“Spanner中的分布式事务”](#spanner)），通过Paxos组执行2PC而不是单独的节点，以提高协议的可用性。
- en: '![dbin 1302](assets/dbin_1302.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![dbin 1302](assets/dbin_1302.png)'
- en: Figure 13-2\. Cohort failure during the propose phase
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图13-2\. 提议阶段期间的队伍失败
- en: The main idea behind 2PC is a *promise* by a cohort that, once it has positively
    responded to the proposal, it will not go back on its decision, so only the coordinator
    can abort the transaction.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 2PC的主要思想是一个**承诺**，即一旦一个队伍积极响应了提议，它将不会反悔，所以只有协调者可以中止事务。
- en: If one of the cohorts has failed *after* accepting the proposal, it has to learn
    about the actual outcome of the vote before it can serve values correctly, since
    the coordinator might have aborted the commit due to the other cohorts’ decisions.
    When a cohort node recovers, it has to get up to speed with a final coordinator
    decision. Usually, this is done by persisting the decision log on the coordinator
    side and replicating decision values to the failed participants. Until then, the
    cohort cannot serve requests because it is in an inconsistent state.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果其中一个队伍在接受提议后失败了，它必须在能正确提供值之前了解投票的实际结果，因为协调者可能因为其他队伍的决定而中止了提交。当队伍节点恢复时，它必须跟上最终协调者的决定。通常，这是通过在协调者端持久化决策日志并将决策值复制到失败的参与者来完成的。在此之前，该队伍不能提供请求，因为它处于不一致状态。
- en: Since the protocol has multiple spots where processes are waiting for the other
    participants (when the coordinator collects votes, or when the cohort is waiting
    for the commit/abort phase), link failures might lead to message loss, and this
    wait will continue indefinitely. If the coordinator does not receive a response
    from the replica during the propose phase, it can trigger a timeout and abort
    the transaction.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 由于协议在多个地方等待其他参与者（当协调者收集投票时，或者队伍在等待提交/中止阶段），链路故障可能导致消息丢失，并且此等待将无限期地继续。如果协调者在提议阶段未收到复制体的响应，它可以触发超时并中止事务。
- en: Coordinator Failures in 2PC
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2PC中的协调者故障
- en: 'If one of the cohorts does not receive a commit or abort command from the coordinator
    during the second phase, as shown in [Figure 13-3](#two_phase_commit_coordinator_failure),
    it should attempt to find out which decision was made by the coordinator. The
    coordinator might have decided upon the value but wasn’t able to communicate it
    to the particular replica. In such cases, information about the decision can be
    replicated from the peers’ transaction logs or from the backup coordinator. Replicating
    commit decisions is safe since it’s always unanimous: the whole point of 2PC is
    to either commit or abort on all sites, and commit on one cohort implies that
    all other cohorts have to commit.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果其中一个队伍在第二阶段未收到协调者的提交或中止命令，如图[13-3](#two_phase_commit_coordinator_failure)所示，它应尝试查明协调者所做的决定。协调者可能已经决定了值，但无法将其通知给特定的复制体。在这种情况下，关于决定的信息可以从对等方的事务日志或备份协调者中复制。复制提交决策是安全的，因为它总是一致的：2PC的整个目的是在所有站点上要么提交要么中止，并且在一个队伍上的提交意味着所有其他队伍都必须提交。
- en: '![dbin 1303](assets/dbin_1303.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![dbin 1303](assets/dbin_1303.png)'
- en: Figure 13-3\. Coordinator failure after the propose phase
  id: totrans-46
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图13-3\. 提议阶段后的协调者故障
- en: During the first phase, the coordinator collects votes and, subsequently, promises
    from cohorts, that they will wait for its explicit commit or abort command. If
    the coordinator fails after collecting the votes, but before broadcasting vote
    results, the cohorts end up in a state of uncertainty. This is shown in [Figure 13-4](#two_phase_commit_coordinator_failure_2).
    Cohorts do not know what precisely the coordinator has decided, and whether or
    not any of the participants (potentially also unreachable) might have been notified
    about the transaction results [[BERNSTEIN87]](app01.html#BERNSTEIN87).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一阶段，协调者收集投票和追随者的承诺，即它们将等待其明确的提交或中止命令。如果协调者在收集投票后但广播投票结果前失败，那么追随者将处于不确定状态。如
    [图 13-4](#two_phase_commit_coordinator_failure_2) 所示。追随者不知道协调者的确切决定是什么，以及是否已经通知了任何参与者（潜在的也可能是不可达的）关于事务结果
    [[BERNSTEIN87]](app01.html#BERNSTEIN87)。
- en: '![dbin 1304](assets/dbin_1304.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![dbin 1304](assets/dbin_1304.png)'
- en: Figure 13-4\. Coordinator failure before it could contact any cohorts
  id: totrans-49
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 13-4\. 在协调者联系到任何追随者之前发生了协调者失败
- en: Inability of the coordinator to proceed with a commit or abort leaves the cluster
    in an undecided state. This means that cohorts will not be able to learn about
    the final decision in case of a permanent coordinator failure. Because of this
    property, we say that 2PC is a *blocking* atomic commitment algorithm. If the
    coordinator never recovers, its replacement has to collect votes for a given transaction
    again, and proceed with a final decision.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 协调者无法继续提交或中止会使集群处于未决状态。这意味着在永久性协调者失败的情况下，追随者将无法了解最终决策。因此我们称两阶段提交为 *阻塞* 原子提交算法。如果协调者永不恢复，其替代者必须重新收集给定事务的投票，并作出最终决定。
- en: 'Many databases use 2PC: MySQL, [PostgreSQL](https://databass.dev/links/6),
    MongoDB,^([2](ch13.html#idm46466885495960)) and others. Two-phase commit is often
    used to implement distributed transactions because of its simplicity (it is easy
    to reason about, implement, and debug) and low overhead (message complexity and
    the number of round-trips of the protocol are low). It is important to implement
    proper recovery mechanisms and have backup coordinator nodes to reduce the chance
    of the failures just described.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 许多数据库使用两阶段提交：MySQL，[PostgreSQL](https://databass.dev/links/6)，MongoDB，^([2](ch13.html#idm46466885495960))
    以及其他。由于其简单性（易于理解、实现和调试）和低开销（消息复杂度和协议的往返次数少），两阶段提交通常用于实现分布式事务。重要的是实施适当的恢复机制并有备份协调者节点以减少上述失败的机会。
- en: Three-Phase Commit
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 三阶段提交
- en: To make an atomic commitment protocol robust against coordinator failures and
    avoid undecided states, the three-phase commit (3PC) protocol adds an extra step,
    and timeouts on *both* sides that can allow cohorts to proceed with either commit
    or abort in the event of coordinator failure, depending on the system state. 3PC
    assumes a synchronous model and that communication failures are not possible [[BABAOGLU93]](app01.html#BABAOGLU93).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使原子提交协议在协调者失败时更加健壮并避免未决状态，三阶段提交（3PC）协议添加了一个额外的步骤，并在 *双方* 都设有超时，这可以让追随者根据系统状态进行提交或中止。3PC
    假设同步模型并且不可能发生通信故障 [[BABAOGLU93]](app01.html#BABAOGLU93)。
- en: 3PC adds a *prepare* phase before the commit/abort step, which communicates
    cohort states collected by the coordinator during the propose phase, allowing
    the protocol to carry on even if the coordinator fails. All other properties of
    3PC and a requirement to have a coordinator for the round are similar to its two-phase
    sibling. Another useful addition to 3PC is timeouts on the cohort side. Depending
    on which step the process is currently executing, either a commit or abort decision
    is forced on timeout.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 三阶段提交在提交/中止步骤之前添加了一个 *准备* 阶段，该阶段在提出阶段由协调者收集的追随者状态，允许协议继续进行即使协调者失败。3PC 的所有其他属性及要求在回合中有协调者与其两阶段的兄弟类似。3PC
    的另一个有用的补充是追随者端的超时。根据当前执行的步骤，超时会强制执行提交或中止决策。
- en: 'As [Figure 13-5](#three_phase_commit_1) shows, the three-phase commit round
    consists of three steps:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [图 13-5](#three_phase_commit_1) 所示，三阶段提交包括三个步骤：
- en: Propose
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 提出
- en: The coordinator sends out a proposed value and collects the votes.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 协调者发送一个建议值并收集投票。
- en: Prepare
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 准备
- en: The coordinator notifies cohorts about the vote results. If the vote has passed
    and all cohorts have decided to commit, the coordinator sends a `Prepare` message,
    instructing them to prepare to commit. Otherwise, an `Abort` message is sent and
    the round completes.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 协调者通知队员有关投票结果。如果投票通过且所有队员决定提交，则协调者发送`Prepare`消息，指示它们准备提交。否则，将发送一个`Abort`消息并完成该轮。
- en: Commit
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 提交
- en: Cohorts are notified by the coordinator to commit the transaction.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 协调者通知队员提交事务。
- en: '![dbin 1305](assets/dbin_1305.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![dbin 1305](assets/dbin_1305.png)'
- en: Figure 13-5\. Three-phase commit
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 13-5\. 三阶段提交
- en: During the *propose* step, similar to 2PC, the coordinator distributes the proposed
    value and collects votes from cohorts, as shown in [Figure 13-5](#three_phase_commit_1).
    If the coordinator crashes during this phase and the operation times out, or if
    one of the cohorts votes negatively, the transaction will be aborted.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在*propose*步骤期间，类似于两阶段提交（2PC），协调者分发建议值并从队员收集投票，如[图 13-5](#three_phase_commit_1)所示。如果协调者在此阶段崩溃并且操作超时，或者其中一个队员投反对票，则事务将被中止。
- en: After collecting the votes, the coordinator makes a decision. If the coordinator
    decides to proceed with a transaction, it issues a `Prepare` command. It may happen
    that the coordinator cannot distribute prepare messages to all cohorts or it fails
    to receive their acknowledgments. In this case, cohorts may abort the transaction
    after timeout, since the algorithm hasn’t moved all the way to the *prepared*
    state.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在收集投票之后，协调者做出决策。如果协调者决定继续事务，则发出`Prepare`命令。可能会出现协调者无法将准备消息分发给所有队员或未能收到其确认的情况。在这种情况下，由于算法未能完全进入*prepared*状态，队员可能会在超时后中止事务。
- en: As soon as all the cohorts successfully move into the prepared state and the
    coordinator has received their prepare acknowledgments, the transaction will be
    committed if either side fails. This can be done since all participants at this
    stage have the same view of the state.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有队员成功进入准备状态并且协调者已收到他们的准备确认，如果任一方失败，事务将被提交。由于此时所有参与者都对状态具有相同的视图，因此可以这样做。
- en: During *commit*, the coordinator communicates the results of the *prepare* phase
    to all the participants, resetting their timeout counters and effectively finishing
    the transaction.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在*commit*阶段期间，协调者向所有参与者通信*prepare*阶段的结果，重置其超时计数器，并有效地完成事务。
- en: Coordinator Failures in 3PC
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 三阶段提交中的协调者故障
- en: 'All state transitions are coordinated, and cohorts can’t move on to the next
    phase until everyone is done with the previous one: the coordinator has to wait
    for the replicas to continue. Cohorts can eventually abort the transaction if
    they do not hear from the coordinator before the timeout, if they didn’t move
    past the prepare phase.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 所有状态转换都是协调的，队员在前一个阶段完成之前不能进入下一个阶段：协调者必须等待副本继续。如果队员在超时前未从协调者那里收到消息，并且未能超过准备阶段，则最终可能会中止事务。
- en: As we discussed previously, 2PC cannot recover from coordinator failures, and
    cohorts may get stuck in a nondeterministic state until the coordinator comes
    back. 3PC avoids blocking the processes in this case and allows cohorts to proceed
    with a deterministic decision.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前讨论的那样，两阶段提交（2PC）无法从协调者故障中恢复，队员可能会陷入非确定性状态，直到协调者回来。三阶段提交（3PC）避免在这种情况下阻塞进程，并允许队员进行确定性决策。
- en: 'The worst-case scenario for the 3PC is a network partition, shown in [Figure 13-6](#three_phase_commit_failure).
    Some nodes successfully move to the prepared state, and now can proceed with commit
    after the timeout. Some can’t communicate with the coordinator, and will abort
    after the timeout. This results in a split brain: some nodes proceed with a commit
    and some abort, all according to the protocol, leaving participants in an inconsistent
    and contradictory state.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 三阶段提交的最坏情况是网络分区，如[图 13-6](#three_phase_commit_failure)所示。一些节点成功进入准备状态，现在可以在超时后继续提交。有些节点无法与协调者通信，并将在超时后中止。这导致了脑裂：一些节点继续提交，一些中止，所有操作都遵循协议，使参与者处于不一致和矛盾的状态。
- en: '![dbin 1306](assets/dbin_1306.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![dbin 1306](assets/dbin_1306.png)'
- en: Figure 13-6\. Coordinator failure during the second phase
  id: totrans-73
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 13-6\. 第二阶段协调者故障
- en: While in theory 3PC does, to a degree, solve the problem with 2PC blocking,
    it has a larger message overhead, introduces potential contradictions, and does
    not work well in the presence of network partitions. This might be the primary
    reason 3PC is not widely used in practice.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然从理论上讲，三阶段提交在一定程度上解决了二阶段提交的阻塞问题，但它具有更大的消息开销，引入潜在矛盾，并且在网络分区存在时工作效果不佳。这可能是三阶段提交在实践中未被广泛使用的主要原因。
- en: Distributed Transactions with Calvin
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Calvin 进行分布式事务
- en: We’ve already touched on the subject of synchronization costs and several ways
    around it. But there are other ways to reduce contention and the total amount
    of time during which transactions hold locks. One of the ways to do this is to
    let replicas agree on the execution order and transaction boundaries before acquiring
    locks and proceeding with execution. If we can achieve this, node failures do
    not cause transaction aborts, since nodes can recover state from other participants
    that execute the same transaction in parallel.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经涉及了同步成本及其几种解决方法的主题。但是还有其他减少争用和事务持有锁时间总量的方法。其中一种方法是在获取锁并进行执行之前，让副本同意执行顺序和事务边界。如果我们能做到这一点，节点故障不会导致事务中止，因为节点可以从并行执行同一事务的其他参与者那里恢复状态。
- en: Traditional database systems execute transactions using two-phase locking or
    optimistic concurrency control and have no deterministic transaction order. This
    means that nodes have to be coordinated to preserve order. Deterministic transaction
    order removes coordination overhead during the execution phase and, since all
    replicas get the same inputs, they also produce equivalent outputs. This approach
    is commonly known as Calvin, a fast distributed transaction protocol [[THOMSON12]](app01.html#THOMSON12).
    One of the prominent examples implementing distributed transactions using Calvin
    is [FaunaDB](https://databass.dev/links/8).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 传统数据库系统使用两阶段锁定或乐观并发控制执行事务，并没有确定性事务顺序。这意味着节点必须协调以保留顺序。确定性事务顺序在执行阶段消除了协调开销，由于所有副本获得相同的输入，它们也会产生等效的输出。这种方法通常称为
    Calvin，一个快速的分布式事务协议 [[THOMSON12]](app01.html#THOMSON12)。通过 Calvin 实现分布式事务的突出例子之一是
    [FaunaDB](https://databass.dev/links/8)。
- en: 'To achieve deterministic order, Calvin uses a *sequencer*: an entry point for
    all transactions. The sequencer determines the order in which transactions are
    executed, and establishes a global transaction input sequence. To minimize contention
    and batch decisions, the timeline is split into *epochs*. The sequencer collects
    transactions and groups them into short time windows (the original paper mentions
    10-millisecond batches), which also become replication units, so transactions
    do not have to be communicated separately.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现确定性顺序，Calvin 使用一个 *顺序器*：所有事务的入口点。顺序器确定事务执行顺序，并建立全局事务输入序列。为了最小化争用并批处理决策，时间轴被分割为
    *时代*。顺序器收集事务并将它们分组到短时间窗口中（原始论文提到 10 毫秒批处理），这也成为复制单元，因此事务不必单独通信。
- en: As soon as a transaction batch is successfully replicated, sequencer forwards
    it to the *scheduler*, which orchestrates transaction execution. The scheduler
    uses a deterministic scheduling protocol that executes parts of transaction in
    parallel, while preserving the serial execution order specified by the sequencer.
    Since applying transaction to a specific state is guaranteed to produce only changes
    specified by the transaction and transaction order is predetermined, replicas
    do not have to further communicate with the sequencer.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦事务批次成功复制，顺序器将其转发给 *调度程序*，后者编排事务执行。调度程序使用确定性调度协议，可以在并行执行事务的同时保留由顺序器指定的串行执行顺序。由于将事务应用到特定状态只会产生事务指定的更改，并且事务顺序是预定的，副本不必进一步与顺序器通信。
- en: Each transaction in Calvin has a *read set* (its dependencies, which is a collection
    of data records from the current database state required to execute it) and a
    *write set* (results of the transaction execution; in other words, its side effects).
    Calvin does not natively support transactions that rely on additional reads that
    would determine read and write sets.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Calvin 中的每个事务都有一个 *读集*（其依赖项，即执行所需的当前数据库状态中的数据记录集合）和一个 *写集*（事务执行的结果；换句话说，它的副作用）。Calvin
    并不原生支持依赖于额外读取的事务，这些读取将确定读写集。
- en: 'A worker thread, managed by the scheduler, proceeds with execution in four
    steps:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 由调度程序管理的工作线程在四个步骤中继续执行：
- en: It analyzes the transaction’s read and write sets, determines node-local data
    records from the read set, and creates the list of *active* participants (i.e.,
    ones that hold the elements of the write set, and will perform modifications on
    the data).
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它分析事务的读取和写入集，确定来自读集的节点本地数据记录，并创建*活动*参与者列表（即持有写集元素并将对数据进行修改的节点）。
- en: It collects the *local* data required to execute the transaction, in other words,
    the read set records that happen to reside on that node. The collected data records
    are forwarded to the corresponding *active* participants.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它收集执行事务所需的*本地*数据，换句话说，发生在该节点上的读集记录。收集的数据记录被转发给相应的*活动*参与者。
- en: If this worker thread is executing on an active participant node, it receives
    data records forwarded from the other participants, as a counterpart of the operations
    executed during step 2.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果此工作线程正在活动参与者节点上执行，则它接收从其他参与者转发的数据记录，作为步骤2执行期间执行的操作的对应。
- en: Finally, it executes a batch of transactions, persisting results into local
    storage. It does not have to forward execution results to the other nodes, as
    they receive the same inputs for transactions and execute and persist results
    locally themselves.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，它执行一个事务批处理，将结果持久化到本地存储。它不必将执行结果转发到其他节点，因为它们接收相同的事务输入并在本地执行和持久化结果。
- en: A typical Calvin implementation colocates sequencer, scheduler, worker, and
    storage subsystems, as [Figure 13-7](#calvin_1) shows. To make sure that sequencers
    reach consensus on exactly which transactions make it into the current epoch/batch,
    Calvin uses the Paxos consensus algorithm (see [“Paxos”](ch14.html#paxos)) or
    asynchronous replication, in which a dedicated replica serves as a leader. While
    using a leader can improve latency, it comes with a higher cost of recovery as
    nodes have to reproduce the state of the failed leader in order to proceed.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的Calvin实现将顺序器、调度器、工作器和存储子系统放置在一起，如[图13-7](#calvin_1)所示。为确保顺序器对当前时期/批次中确切进入的事务达成共识，Calvin使用Paxos共识算法（参见[“Paxos”](ch14.html#paxos)）或异步复制，在这种复制中，专用副本充当领导者。尽管使用领导者可以提高延迟，但在节点必须重现失败领导者的状态以继续时，它带来了更高的恢复成本。
- en: '![dbin 1307](assets/dbin_1307.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![dbin 1307](assets/dbin_1307.png)'
- en: Figure 13-7\. Calvin architecture
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图13-7\. Calvin架构
- en: Distributed Transactions with Spanner
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spanner的分布式事务
- en: Calvin is often contrasted with another approach for distributed transaction
    management called Spanner [[CORBETT12]](app01.html#CORBETT12). Its implementations
    (or derivatives) include several open source databases, most prominently [CockroachDB](https://databass.dev/links/9)
    and [YugaByte DB](https://databass.dev/links/10). While Calvin establishes the
    global transaction execution order by reaching consensus on sequencers, Spanner
    uses two-phase commit over consensus groups per partition (in other words, per
    shard). Spanner has a rather complex setup, and we only cover high-level details
    in the scope of this book.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Calvin经常与另一种分布式事务管理方法Spanner进行对比[[CORBETT12]](app01.html#CORBETT12)。其实现（或衍生版本）包括几个开源数据库，最显著的是[CockroachDB](https://databass.dev/links/9)和[YugaByte
    DB](https://databass.dev/links/10)。Calvin通过在顺序器上达成共识来建立全局事务执行顺序，而Spanner则在每个分区（即每个分片）上使用共识组的两阶段提交。Spanner的设置相当复杂，在本书的范围内我们只涵盖高层次的细节。
- en: 'To achieve consistency and impose transaction order, Spanner uses *TrueTime*:
    a high-precision wall-clock API that also exposes an uncertainty bound, allowing
    local operations to introduce artificial slowdowns to wait for the uncertainty
    bound to pass.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现一致性并强加事务顺序，Spanner使用*TrueTime*：一个高精度的挂钟API，还公开一个不确定性边界，允许本地操作引入人为减速以等待不确定性边界过去。
- en: 'Spanner offers three main operation types: *read-write transactions*, *read-only
    transactions*, and *snapshot reads*. Read-write transactions require locks, pessimistic
    concurrency control, and presence of the leader replica. Read-only transactions
    are lock-free and can be executed at any replica. A leader is required only for
    reads at the *latest* timestamp, which takes the latest committed value from the
    Paxos group. Reads at the specific timestamp are consistent, since values are
    versioned and snapshot contents can’t be changed once written. Each data record
    has a timestamp assigned, which holds a value of the transaction commit time.
    This also implies that multiple timestamped versions of the record can be stored.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Spanner提供三种主要操作类型：*读写事务*，*只读事务*和*快照读取*。读写事务需要锁定，悲观并发控制，并且需要领导副本的存在。只读事务无需锁定，并且可以在任何副本上执行。仅在需要在*最新*时间戳处读取时才需要领导者，这会获取Paxos组中最新提交的值。在特定时间戳处的读取是一致的，因为值被版本化，且快照内容一旦写入就无法更改。每个数据记录都有一个分配的时间戳，它保存了事务提交时间的值。这也意味着可以存储记录的多个时间戳版本。
- en: '[Figure 13-8](#spanner_1) shows the Spanner architecture. Each *spanserver*
    (replica, a server instance that serves data to clients) holds several *tablets*,
    with Paxos (see [“Paxos”](ch14.html#paxos)) state machines attached to them. Replicas
    are grouped into replica sets called Paxos groups, a unit of data placement and
    replication. Each Paxos group has a long-lived leader (see [“Multi-Paxos”](ch14.html#multi_paxos)).
    Leaders communicate with each other during multishard transactions.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 13-8](#spanner_1) 展示了Spanner架构。每个*spanserver*（副本，为客户端提供数据服务的服务器实例）持有多个*tablet*，每个tablet上附加了Paxos状态机（见[“Paxos”](ch14.html#paxos)）。副本被分组成称为Paxos组的副本集，这是数据放置和复制的单位。每个Paxos组都有一个长期存在的领导者（见[“Multi-Paxos”](ch14.html#multi_paxos)）。领导者在多分片事务期间相互通信。'
- en: '![dbin 1308](assets/dbin_1308.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![dbin 1308](assets/dbin_1308.png)'
- en: Figure 13-8\. Spanner architecture
  id: totrans-95
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 13-8\. Spanner架构
- en: Every write has to go through the Paxos group leader, while reads can be served
    directly from the tablet on up-to-date replicas. The leader holds a *lock table*
    that is used to implement concurrency control using the two-phase locking (see
    [“Lock-Based Concurrency Control”](ch05.html#lock_based_cc)) mechanism and a *transaction
    manager* that is responsible for multishard distributed transactions. Operations
    that require synchronization (such as writes and reads within a transaction) have
    to acquire the locks from the lock table, while other operations (snapshot reads)
    can access the data directly.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 每次写操作都必须通过Paxos组的领导者进行，而读操作可以直接从最新的复制副本上的平板提供服务。领导者持有一个*锁表*，用于使用两阶段锁定（见[“基于锁的并发控制”](ch05.html#lock_based_cc)）机制实现并发控制，以及一个*事务管理器*，负责多分片分布式事务。需要同步的操作（例如事务内的写入和读取）必须从锁表中获取锁，而其他操作（快照读取）可以直接访问数据。
- en: For multishard transactions, group leaders have to coordinate and perform a
    two-phase commit to ensure consistency, and use two-phase locking to ensure isolation.
    Since the 2PC algorithm requires the presence of all participants for a successful
    commit, it hurts availability. Spanner solves this by using Paxos groups rather
    than individual nodes as cohorts. This means that 2PC can continue operating even
    if some of the members of the group are down. Within the Paxos group, 2PC contacts
    only the node that serves as a leader.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多分片事务，组领导者必须协调并执行两阶段提交以确保一致性，并使用两阶段锁定以确保隔离性。由于2PC算法要求所有参与者都在场才能成功提交，这会影响可用性。Spanner通过使用Paxos组而不是单个节点作为同行解决了这个问题。这意味着即使组的某些成员宕机，2PC也可以继续运行。在Paxos组内，2PC仅与充当领导者的节点联系。
- en: Paxos groups are used to consistently replicate transaction manager states across
    multiple nodes. The Paxos leader first acquires write locks, and chooses a write
    timestamp that is guaranteed to be larger than any previous transactions’ timestamp,
    and records a 2PC `prepare` entry through Paxos. The transaction coordinator collects
    timestamps and generates a commit timestamp that is greater than any of the prepare
    timestamps, and logs a `commit` entry through Paxos. It then waits until *after*
    the timestamp it has chosen for commit, since it has to guarantee that clients
    will only see transaction results whose timestamps are in the past. After that,
    it sends this timestamp to the client and leaders, which log the `commit` record
    with the new timestamp in their local Paxos group and are now free to release
    the locks.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Paxos 组用于在多个节点之间一致地复制事务管理器状态。Paxos 领导者首先获取写锁，并选择一个写入时间戳，该时间戳保证大于任何先前事务的时间戳，并通过
    Paxos 记录一个`prepare`条目。事务协调器收集时间戳，并生成一个大于所有准备时间戳的提交时间戳，并通过 Paxos 记录一个`commit`条目。然后，它等待直到选择的提交时间戳之后，因为它必须保证客户端只会看到过去时间戳的事务结果。之后，它将这个时间戳发送给客户端和领导者，它们在本地
    Paxos 组中记录带有新时间戳的`commit`记录，并可以释放锁。
- en: Single-shard transactions do not have to consult the transaction manager (and,
    subsequently, do not have to perform a cross-partition two-phase commit), since
    consulting a Paxos group and a lock table is enough to guarantee transaction order
    and consistency within the shard.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 单分片事务不必咨询事务管理器（因此也不必执行跨分区两阶段提交），因为咨询 Paxos 组和锁表足以保证分片内的事务顺序和一致性。
- en: 'Spanner read-write transactions offer a serialization order called *external
    consistency*: transaction timestamps reflect serialization order, even in cases
    of distributed transactions. External consistency has real-time properties equivalent
    to linearizability: if transaction `T[1]` commits before `T[2]` starts, `T[1]`’s
    timestamp is smaller than the timestamp of `T[2]`.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Spanner 读写事务提供称为*外部一致性*的串行化顺序：事务时间戳反映串行化顺序，即使在分布式事务的情况下也是如此。外部一致性具有与线性一致性相等的实时属性：如果事务`T[1]`在事务`T[2]`开始之前提交，则`T[1]`的时间戳小于`T[2]`的时间戳。
- en: To summarize, Spanner uses Paxos for consistent transaction log replication,
    two-phase commit for cross-shard transactions, and TrueTime for deterministic
    transaction ordering. This means that multipartition transactions have a higher
    cost due to an additional two-phase commit round, compared to Calvin [[ABADI17]](app01.html#ABADI17).
    Both approaches are important to understand since they allow us to perform transactions
    in partitioned distributes data stores.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，Spanner 使用 Paxos 进行一致的事务日志复制，使用两阶段提交进行跨分片事务，并使用 TrueTime 进行确定性事务排序。这意味着由于额外的两阶段提交轮次，多分片事务具有更高的成本，与
    Calvin 相比[[ABADI17]](app01.html#ABADI17)。理解这两种方法非常重要，因为它们允许我们在分区分布式数据存储中执行事务。
- en: Database Partitioning
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据库分区
- en: 'While discussing Spanner and Calvin, we’ve been using the term *partitioning*
    quite heavily. Let’s now discuss it in more detail. Since storing all database
    records on a single node is rather unrealistic for the majority of modern applications,
    many databases use partitioning: a logical division of data into smaller manageable
    segments.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论 Spanner 和 Calvin 时，我们一直在大量使用*分区*这个术语。现在让我们更详细地讨论它。由于将所有数据库记录存储在单个节点上对于大多数现代应用程序来说是不切实际的，许多数据库使用分区：将数据逻辑地分成更小的可管理段。
- en: 'The most straightforward way to partition data is by splitting it into ranges
    and allowing *replica sets* to manage only specific ranges (partitions). When
    executing queries, clients (or query coordinators) have to route requests based
    on the *routing key* to the correct replica set for both reads and writes. This
    partitioning scheme is typically called *sharding*: every replica set acts as
    a single source for a subset of data.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 分区数据最直接的方法是将其分割成范围，并允许*复制集*管理特定范围（分区）。在执行查询时，客户端（或查询协调器）必须基于*路由键*将请求路由到正确的复制集，用于读取和写入。这种分区方案通常称为*分片*：每个复制集充当数据子集的单一来源。
- en: To use partitions most effectively, they have to be sized, taking the load and
    value distribution into consideration. This means that frequently accessed, read/write
    heavy ranges can be split into smaller partitions to spread the load between them.
    At the same time, if some value ranges are more dense than other ones, it might
    be a good idea to split them into smaller partitions as well. For example, if
    we pick *zip code* as a routing key, since the country population is unevenly
    spread, some zip code ranges can have more data (e.g., people and orders) assigned
    to them.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 要最有效地使用分区，它们必须被大小化，考虑负载和值的分布。这意味着经常访问、读写重的范围可以被分割成更小的分区以在它们之间分散负载。同时，如果某些值范围比其他值范围更密集，将它们分割成更小的分区也可能是一个好主意。例如，如果我们选择*邮政编码*作为路由键，由于国家人口分布不均匀，一些邮政编码范围可能分配了更多的数据（例如，人员和订单）。
- en: When nodes are added to or removed from the cluster, the database has to re-partition
    the data to maintain the balance. To ensure consistent movements, we should relocate
    the data before we update the cluster metadata and start routing requests to the
    new targets. Some databases perform *auto-sharding* and relocate the data using
    placement algorithms that determine optimal partitioning. These algorithms use
    information about read, write loads, and amounts of data in each shard.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 当节点被添加到或从集群中移除时，数据库需要重新分区数据以保持平衡。为了确保一致的移动，我们应该在更新集群元数据并开始将请求路由到新目标之前，重新定位数据。一些数据库执行*自动分片*并使用确定最佳分区的放置算法来重新定位数据。这些算法利用有关每个分片中读取、写入负载和数据量的信息。
- en: To find a target node from the routing key, some database systems compute a
    *hash* of the key, and use some form of mapping from the hash value to the node
    ID. One of the advantages of using the hash functions for determining replica
    placement is that it can help to reduce range hot-spotting, since hash values
    do not sort the same way as the original values. While two lexicographically close
    routing keys would be placed at the same replica set, using hashed values would
    place them on different ones.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从路由键中找到目标节点，一些数据库系统计算键的*哈希*，并使用某种形式的映射从哈希值到节点ID。使用哈希函数确定副本放置的一个优点是，它有助于减少范围热点，因为哈希值与原始值的排序方式不同。虽然两个词典上接近的路由键将被放置在同一个副本集中，但使用哈希值将它们放置在不同的副本集中。
- en: The most straightforward way to map hash values to node IDs is by taking a remainder
    of the division of the hash value by the size of the cluster (modulo). If we have
    `N` nodes in the system, the target node ID is picked by computing `hash(v) modulo
    N`. The main problem with this approach is that whenever nodes are added or removed
    and the cluster size changes from `N` to `N’`, many values returned by `hash(v)
    modulo N’` will differ from the original ones. This means that most of the data
    will have to be moved.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 将哈希值映射到节点ID的最直接方法是通过取哈希值除以集群大小的余数。如果系统中有`N`个节点，目标节点ID通过计算`hash(v) modulo N`来选择。这种方法的主要问题是，每当节点被添加或移除，并且集群大小从`N`变为`N'`时，由`hash(v)
    modulo N'`返回的许多值将与原始值不同。这意味着大部分数据将不得不被移动。
- en: Consistent Hashing
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一致性哈希
- en: In order to mitigate this problem, some databases, such as Apache Cassandra
    and Riak (among others), use a different partitioning scheme called *consistent
    hashing*. As previously mentioned, routing key values are hashed. Values returned
    by the hash function are mapped to a *ring*, so that after the largest possible
    value, it wraps around to its smallest value. Each node gets its own position
    on the ring and becomes responsible for the *range* of values, between its predecessor’s
    and its own positions.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 为了缓解这个问题，一些数据库，如Apache Cassandra和Riak（等等），使用了一种称为*一致性哈希*的不同分区方案。正如之前提到的，路由键值被哈希了。哈希函数返回的数值被映射到一个*环*上，使得在最大可能的数值之后，它会回到最小的数值。每个节点在环上都有自己的位置，并负责其前任和自己位置之间的*范围*的数值。
- en: 'Using consistent hashing helps to reduce the number of relocations required
    for maintaining balance: a change in the ring affects only the *immediate neighbors*
    of the leaving or joining node, and not an entire cluster. The word *consistent*
    in the definition implies that, when the hash table is resized, if we have `K`
    possible hash keys and `n` nodes, on average we have to relocate only `K/n` keys.
    In other words, a consistent hash function output changes minimally as the function
    range changes [[KARGER97]](app01.html#KARGER97).'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一致性哈希有助于减少需要维护平衡的重定位数量：环中的变化仅影响离开或加入节点的*直接邻居*，而不是整个集群。定义中的词语*一致*意味着，当哈希表调整大小时，如果我们有`K`个可能的哈希键和`n`个节点，平均只需要重新定位`K/n`个键。换句话说，一致哈希函数的输出在函数范围变化时变化很小
    [[KARGER97]](app01.html#KARGER97)。
- en: Distributed Transactions with Percolator
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Percolator的分布式事务
- en: Coming back to the subject of distributed transactions, isolation levels might
    be difficult to reason about because of the allowed read and write anomalies.
    If serializability is not required by the application, one of the ways to avoid
    the write anomalies described in SQL-92 is to use a transactional model called
    *snapshot isolation* (SI).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 回到分布式事务的主题，由于允许的读取和写入异常，隔离级别可能难以理解。如果应用程序不需要串行化，避免在SQL-92中描述的写入异常的一种方法是使用称为*快照隔离*（SI）的事务模型。
- en: Snapshot isolation guarantees that all reads made within the transaction are
    consistent with a snapshot of the database. The snapshot contains all values that
    were *committed before* the transaction’s start timestamp. If there’s a *write-write
    conflict* (i.e., when two concurrently running transactions attempt to make a
    write to the same cell), only one of them will commit. This characteristic is
    usually referred to as *first committer wins*.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 快照隔离确保事务中的所有读取都与数据库的快照一致。该快照包含在事务开始时间戳之前*提交的所有值*。如果存在*写-写冲突*（即两个并发运行的事务试图对同一单元格进行写入），只有其中一个会提交。这种特性通常被称为*先提交者优先*。
- en: Snapshot isolation prevents *read skew*, an anomaly permitted under the read-committed
    isolation level. For example, a sum of `x` and `y` is supposed to be `100`. Transaction
    `T1` performs an operation `read(x)`, and reads the value `70`. `T2` updates two
    values `write(x, 50)` and `write(y, 50)`, and commits. If `T1` attempts to run
    `read(y)`, and proceeds with transaction execution based on the value of `y` (`50`),
    newly committed by `T2`, it will lead to an inconsistency. The value of `x` that
    `T1` has read *before* `T2` committed and the new value of `y` aren’t consistent
    with each other. Since snapshot isolation only makes values up to a specific timestamp
    visible for transactions, the new value of `y`, `50`, won’t be visible to `T1`
    [[BERENSON95]](app01.html#BERENSON95).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 快照隔离防止*读取偏斜*，这是在读取提交隔离级别下允许的异常情况。例如，假设`x`和`y`的总和应为`100`。事务`T1`执行`read(x)`操作，并读取值`70`。`T2`更新两个值`write(x,
    50)`和`write(y, 50)`，并提交。如果`T1`尝试运行`read(y)`，并根据由`T2`新提交的值`y`（`50`）进行事务执行，这将导致不一致性。`T1`在`T2`提交之前读取的值`x`和`y`的新值不一致。由于快照隔离仅使事务能够看到特定时间戳之前的值，`y`的新值`50`对`T1`是不可见的
    [[BERENSON95]](app01.html#BERENSON95)。
- en: 'Snapshot isolation has several convenient properties:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 快照隔离具有几个便利的特性：
- en: It allows *only* repeatable reads of committed data.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它*仅*允许对已提交数据进行可重复读取。
- en: Values are consistent, as they’re read from the snapshot at a specific timestamp.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值是一致的，因为它们是从特定时间戳的快照中读取的。
- en: Conflicting writes are aborted and retried to prevent inconsistencies.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 冲突的写入被中止并重试，以防止不一致性。
- en: Despite that, histories under snapshot isolation are *not* serializable. Since
    only conflicting writes to the *same cells* are aborted, we can still end up with
    a *write skew* (see [“Read and Write Anomalies”](ch05.html#read_write_anomalies)).
    Write skew occurs when two transactions modify disjoint sets of values, each preserving
    invariants for the data it writes. Both transactions are allowed to commit, but
    a combination of writes performed by these transactions may violate these invariants.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，快照隔离下的历史*不*是可串行化的。由于仅中止对*同一单元格*的冲突写入，我们仍然可能遇到*写入偏斜*（见[“读取和写入异常”](ch05.html#read_write_anomalies)）。当两个事务修改不相交的值集时，保持每个写入的数据不变。允许这两个事务都提交，但这些事务执行的写入组合可能违反这些不变量。
- en: Snapshot isolation provides semantics that can be useful for many applications
    and has the major advantage of efficient reads, because no locks have to be acquired
    since snapshot data cannot be changed.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 快照隔离提供了对许多应用有用的语义，并具有高效读取的主要优势，因为由于快照数据不可更改，无需获取锁。
- en: '*Percolator* is a library that implements a transactional API on top of the
    distributed database *Bigtable* (see [“Wide Column Stores”](ch01.html#wide_column_stores)).
    This is a great example of building a transaction API on top of the existing system.
    Percolator stores data records, committed data point locations (write metadata),
    and locks in different columns. To avoid race conditions and reliably lock tables
    in a single RPC call, it uses a conditional mutation Bigtable API that allows
    it to perform read-modify-write operations with a single remote call.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '*Percolator* 是一个在分布式数据库 *Bigtable* 上实现事务 API 的库（参见[“宽列存储”](ch01.html#wide_column_stores)）。这是在现有系统上构建事务
    API 的一个很好的例子。Percolator 在不同列中存储数据记录、已提交数据点位置（写入元数据）和锁。为了避免竞态条件并可靠地在单个远程调用中锁定表格，它使用了条件突变的
    Bigtable API，允许它执行带有单个远程调用的读取-修改-写入操作。'
- en: 'Each transaction has to consult the *timestamp oracle* (a source of clusterwide-consistent
    monotonically increasing timestamps) twice: for a transaction start timestamp,
    and during commit. Writes are buffered and committed using a client-driven two-phase
    commit (see [“Two-Phase Commit”](#two_phase_commit)).'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 每个事务必须两次咨询*时间戳预言机*（一个提供集群范围一致单调递增时间戳的源）：用于事务开始时间戳，并在提交期间。写入被缓冲并使用客户端驱动的两阶段提交进行提交（参见[“两阶段提交”](#two_phase_commit)）。
- en: '[Figure 13-9](#percolator_1) shows how the contents of the table change during
    execution of the transaction steps:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 13-9](#percolator_1) 显示了在执行事务步骤期间表格内容如何更改：'
- en: a) Initial state. After the execution of the previous transaction, `TS1` is
    the latest timestamp for both accounts. No locks are held.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: a) 初始状态。在执行前一个事务后，`TS1` 是两个帐户的最新时间戳。没有锁被保持。
- en: 'b) The first phase, called *prewrite*. The transaction attempts to acquire
    locks for all cells written during the transaction. One of the locks is marked
    as *primary* and is used for client recovery. The transaction checks for the possible
    conflicts: if any other transaction has already written any data with a later
    timestamp or there are unreleased locks at any timestamp. If any conflict is detected,
    the transaction aborts.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: b) 第一阶段，称为*预写入*。事务尝试为事务期间写入的所有单元格获取锁。其中一个锁标记为*主要*，用于客户端恢复。事务检查可能的冲突：如果任何其他事务已经使用更晚的时间戳写入任何数据或者在任何时间戳有未释放的锁。如果检测到任何冲突，则事务中止。
- en: c) If all locks were successfully acquired and the possibility of conflict is
    ruled out, the transaction can continue. During the second phase, the client releases
    its locks, starting with the primary one. It publishes its write by replacing
    the lock with a write record, updating write metadata with the timestamp of the
    latest data point.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: c) 如果成功获取了所有锁，并排除了冲突的可能性，事务可以继续。在第二阶段期间，客户端释放其锁，从主锁开始。它通过用写记录替换锁，更新写入元数据为最新数据点的时间戳来发布其写入。
- en: Since the client may fail while trying to commit the transaction, we need to
    make sure that partial transactions are finalized or rolled back. If a later transaction
    encounters an incomplete state, it should attempt to release the primary lock
    and commit the transaction. If the primary lock is already released, transaction
    contents *have to be* committed. Only one transaction can hold a lock at a time
    and all state transitions are atomic, so situations in which two transactions
    attempt to perform operations on the contents are not possible.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 由于客户端在尝试提交事务时可能失败，我们需要确保部分事务得到最终确认或回滚。如果后续事务遇到不完整状态，应尝试释放主锁并提交事务。如果主锁已释放，则必须提交事务内容。一次只能有一个事务持有锁，并且所有状态转换都是原子的，因此不可能出现两个事务尝试对内容执行操作的情况。
- en: '![dbin 1309](assets/dbin_1309.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![dbin 1309](assets/dbin_1309.png)'
- en: Figure 13-9\. Percolator transaction execution steps. Transaction credits $150
    from Account2 and debits it to Account1.
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 13-9\. Percolator 事务执行步骤。事务从 Account2 账户中扣除 $150，并将其记入 Account1 账户。
- en: Snapshot isolation is an important and useful abstraction, commonly used in
    transaction processing. Since it simplifies semantics, precludes some of the anomalies,
    and opens up an opportunity to improve concurrency and performance, many MVCC
    systems offer this isolation level.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 快照隔离是一个重要且有用的抽象，在事务处理中常用。因为它简化了语义，排除了一些异常情况，并提供了提高并发性和性能的机会，许多MVCC系统提供这种隔离级别。
- en: One of the examples of databases based on the Percolator model is [TiDB](https://databass.dev/links/11)
    (“Ti” stands for Titatium). TiDB is a strongly consistent, highly available, and
    horizontally scalable open source database, compatible with MySQL.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 基于Percolator模型的数据库示例之一是[TiDB](https://databass.dev/links/11)（“Ti”代表Titanium）。TiDB是一个高度一致、高可用且横向可扩展的开源数据库，与MySQL兼容。
- en: Coordination Avoidance
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 协调避免
- en: One more example, discussing costs of serializability and attempting to reduce
    the amount of coordination while still providing strong consistency guarantees,
    is coordination avoidance [[BAILIS14b]](app01.html#BAILIS14b). Coordination can
    be avoided, while preserving data integrity constraints, if operations are invariant
    confluent. Invariant Confluence (*I*-Confluence) is defined as a property that
    ensures that two invariant-valid but diverged database states can be merged into
    a single valid, final state. Invariants in this case preserve consistency in ACID
    terms.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是讨论可串行化成本并试图减少协调量同时仍提供强一致性保证的尝试是协调避免[[BAILIS14b]](app01.html#BAILIS14b)。如果操作是不变一致的，可以避免协调，同时保留数据完整性约束。不变一致（*I*-Confluence）被定义为一种属性，确保两个满足不变性但状态分歧的数据库状态可以合并为一个单一有效的最终状态。在这种情况下，不变性保持了ACID术语中的一致性。
- en: Because any two valid states can be merged into a valid state, *I*-Confluent
    operations can be executed without additional coordination, which significantly
    improves performance characteristics and scalability potential.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 因为任何两个有效状态都可以合并为一个有效状态，*I*-Confluent操作可以在没有额外协调的情况下执行，这显著提高了性能特性和可扩展性潜力。
- en: To preserve this invariant, in addition to defining an operation that brings
    our database to the new state, we have to define a *merge* function that accepts
    two states. This function is used in case states were updated independently and
    bring diverged states back to convergence.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持这种不变性，除了定义将我们的数据库带入新状态的操作外，我们还必须定义一个*merge*函数，该函数接受两个状态。这个函数用于在状态独立更新并使得状态分歧时将它们合并为一致状态。
- en: 'Transactions are executed against the local database versions (snapshots).
    If a transaction requires any state from other partitions for execution, this
    state is made available for it locally. If a transaction commits, resulting changes
    made to the local snapshot are migrated and merged with the snapshots on the other
    nodes. A system model that allows coordination avoidance has to guarantee the
    following properties:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 事务是针对本地数据库版本（快照）执行的。如果事务执行需要来自其他分区的任何状态，则此状态会在本地提供给它。如果事务提交，则将对本地快照进行的更改迁移并与其他节点上的快照合并。允许协调避免的系统模型必须保证以下属性：
- en: Global validity
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 全局有效性
- en: Required invariants are always satisfied, for both merged and divergent committed
    database states, and transactions cannot observe invalid states.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 所需不变性始终得到满足，对于合并和分歧的已提交数据库状态，事务不能观察到无效状态。
- en: Availability
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 可用性
- en: If all nodes holding states are reachable by the client, the transaction has
    to reach a commit decision, or abort, if committing it would violate one of the
    transaction invariants.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果客户端可以访问所有持有状态的节点，则事务必须达到提交决定，或者如果提交可能违反事务不变量，则中止。
- en: Convergence
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 收敛
- en: Nodes can maintain their local states independently, but in the absence of further
    transactions and indefinite network partitions, they have to be able to reach
    the same state.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 节点可以独立地维护其本地状态，但在没有进一步的事务和无限期的网络分区的情况下，它们必须能够达到相同的状态。
- en: Coordination freedom
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 协调自由
- en: Local transaction execution is independent from the operations against the local
    states performed on behalf of the other nodes.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 本地事务执行与代表其他节点执行的操作对本地状态的影响是独立的。
- en: One of the examples of implementing coordination avoidance is Read-Atomic Multi
    Partition (RAMP) transactions [[BAILIS14c]](app01.html#BAILIS14c). RAMP uses multiversion
    concurrency control and metadata of current in-flight operations to fetch any
    missing state updates from other nodes, allowing read and write operations to
    be executed concurrently. For example, readers that overlap with some writer modifying
    the same entry can be detected and, if necessary, *repaired* by retrieving required
    information from the in-flight write metadata in an additional round of communication.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 实现协调避免的一个例子是读-原子多分区（RAMP）事务[[BAILIS14c]](app01.html#BAILIS14c)。RAMP使用多版本并发控制和当前正在进行的操作的元数据来获取来自其他节点的任何丢失状态更新，允许读和写操作同时执行。例如，可以检测到与修改同一条目的某个写入重叠的读取器，并且如果必要，可以通过在额外的通信回合中从正在进行的写入元数据中检索所需信息来*修复*它们。
- en: 'Using lock-based approaches in a distributed environment might be not the best
    idea, and instead of doing that, RAMP provides two properties:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式环境中使用基于锁的方法可能不是最好的主意，而RAMP提供了两个属性而不是这样做：
- en: Synchronization independence
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 同步独立性
- en: One client’s transactions won’t stall, abort, or force the other client’s transactions
    to wait.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 一个客户端的事务不会停滞、中止或者迫使其他客户端的事务等待。
- en: Partition independence
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 分区独立性
- en: Clients do not have to contact partitions whose values aren’t involved in their
    transactions.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 客户无需联系不涉及其交易的分区值。
- en: 'RAMP introduces the *read atomic* isolation level: transactions cannot observe
    any in-process state changes from in-flight, uncommitted, and aborted transactions.
    In other words, all (or none) transaction updates are visible to concurrent transactions.
    By that definition, the read atomic isolation level also precludes *fractured
    reads*: when a transaction observes only a subset of writes executed by some other
    transaction.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: RAMP引入了*读原子*隔离级别：事务不能观察来自正在进行、未提交和已中止事务的任何正在进行的状态更改。换句话说，所有（或者没有）事务更新对并发事务可见。按照这一定义，读原子隔离级别也排除了*碎片化读*：当一个事务仅观察到另一个事务执行的部分写入时。
- en: RAMP offers atomic write visibility without requiring mutual exclusion, which
    other solutions, such as distributed locks, often couple together. This means
    that transactions can proceed without stalling each other.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: RAMP提供了原子写入可见性，而无需互斥，这与其他解决方案（如分布式锁）经常耦合在一起。这意味着事务可以在不阻碍彼此的情况下继续进行。
- en: RAMP distributes transaction metadata that allows reads to detect concurrent
    in-flight writes. By using this metadata, transactions can detect the presence
    of newer record versions, find and fetch the latest ones, and operate on them.
    To avoid coordination, all local commit decisions must also be valid globally.
    In RAMP, this is solved by requiring that, by the time a write becomes visible
    in one partition, writes from the same transaction in all other involved partitions
    are also visible for readers in those partitions.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: RAMP分发事务元数据，允许读操作检测并发进行中的写入。通过使用此元数据，事务可以检测到更新的最新记录版本，找到并获取最新的记录，并对其进行操作。为了避免协调，所有本地提交决策也必须在全局范围内有效。在RAMP中，通过要求一旦写入在一个分区中变得可见，同一事务在所有其他涉及的分区中的写入对那些分区的读者也必须可见来解决这个问题。
- en: 'To allow readers and writers to proceed without blocking other concurrent readers
    and writers, while maintaining the read atomic isolation level both locally and
    system-wide (in all other partitions modified by the committing transaction),
    writes in RAMP are installed and made visible using two-phase commit:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 为了允许读者和写者在不阻塞其他并发读者和写者的情况下继续进行，并且在全局范围内保持读原子隔离级别（在提交事务修改的所有其他分区中），在RAMP中使用两阶段提交安装并使写入可见：
- en: Prepare
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 准备
- en: The first phase prepares and places writes to their respective target partitions
    without making them visible.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 第一阶段准备并将写入放置到其各自的目标分区中，而不使其可见。
- en: Commit/abort
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 提交/中止
- en: The second phase publishes the state changes made by the write operation of
    the committing transaction, making them available atomically across all partitions,
    or rolls back the changes.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 第二阶段发布提交事务写操作所做的状态更改，使其在所有分区中原子地可用，或者回滚这些更改。
- en: 'RAMP allows multiple versions of the same record to be present at any given
    moment: latest value, in-flight uncommitted changes, and stale versions, overwritten
    by later transactions. Stale versions have to be kept around only for in-progress
    read requests. As soon as all concurrent readers complete, stale values can be
    discarded.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: RAMP允许同一记录的多个版本同时存在：最新值、正在进行的未提交更改和被后续事务覆盖的旧版本。过时的版本只需要在进行中的读请求完成后保留。一旦所有并发读取完成，过时的值就可以被丢弃。
- en: Making distributed transactions performant and scalable is difficult because
    of the coordination overhead associated with preventing, detecting, and avoiding
    conflicts for the concurrent operations. The larger the system, or the more transactions
    it attempts to serve, the more overhead it incurs. The approaches described in
    this section attempt to reduce the amount of coordination by using invariants
    to determine where coordination can be avoided, and only paying the full price
    if it’s absolutely necessary.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 由于协调重复操作的成本增加，使分布式事务具备良好的性能和可扩展性是困难的。系统越大，或者试图服务的事务越多，协调的开销就越大。本节描述的方法尝试通过使用不变量来减少协调的量，并且只在绝对必要时才支付全部成本。
- en: Summary
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we discussed several ways of implementing distributed transactions.
    First, we discussed two atomic commitment algorithms: two- and three-phase commits.
    The big advantage of these algorithms is that they’re easy to understand and implement,
    but have several shortcomings. In 2PC, a coordinator (or at least its substitute)
    has to be alive for the length of the commitment process, which significantly
    reduces availability. 3PC lifts this requirement for some cases, but is prone
    to split brain in case of network partition.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了几种实现分布式事务的方法。首先，我们讨论了两种原子提交算法：二阶段和三阶段提交。这些算法的主要优势在于它们易于理解和实现，但也存在一些缺点。在二阶段提交中，协调者（或其替代者）必须在提交过程中保持活动状态，这显著降低了可用性。而三阶段提交在某些情况下解除了此要求，但在网络分区时容易出现脑裂现象。
- en: Distributed transactions in modern database systems are often implemented using
    consensus algorithms, which we’re going to discuss in the next chapter. For example,
    both Calvin and Spanner, discussed in this chapter, use Paxos.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现代数据库系统中的分布式事务通常使用共识算法实现，我们将在下一章中讨论这些算法。例如，本章中讨论的Calvin和Spanner都使用了Paxos算法。
- en: Consensus algorithms are more involved than atomic commit ones, but have much
    better fault-tolerance properties, and decouple decisions from their initiators
    and allow participants to decide on *a value* rather than on whether or not to
    accept *the value* [[GRAY04]](app01.html#GRAY04).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 共识算法比原子提交算法更复杂，但具有更好的容错性，并且将决策与其发起者分离，并允许参与者决定*一个值*而不是接受*该值* [[GRAY04]](app01.html#GRAY04)。
- en: ^([1](ch13.html#idm46466885552408-marker)) The fine print says “assuming a highly
    reliable network.” In other words, a network that precludes partitions [ALHOUMAILY10].
    Implications of this assumption are discussed in the paper’s section about algorithm
    description.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch13.html#idm46466885552408-marker)) 细则中提到“假设有一个高度可靠的网络”。换句话说，这是一个排除分区的网络
    [ALHOUMAILY10]。这种假设的影响在文章的算法描述部分进行了讨论。
- en: '^([2](ch13.html#idm46466885495960-marker)) However, the documentation says
    that as of v3.6, 2PC provides only transaction-*like* semantics: [*https://databass.dev/links/7*](https://databass.dev/links/7).'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch13.html#idm46466885495960-marker)) 然而，文档中指出，截至v3.6，二阶段提交仅提供类似事务的语义：[*https://databass.dev/links/7*](https://databass.dev/links/7)。
