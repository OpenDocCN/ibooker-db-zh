# 第三章：数据

本章开始了第二部分旅程：*间接查询优化*。如 “优化查询响应时间” 中所述，直接查询优化解决了许多问题，但并非所有问题。即使你已经超越了第二章中关于直接查询优化的知识和技能，你仍然会遇到简单且适当索引但仍然缓慢的查询。这时你开始优化*环绕*查询，从它访问的数据开始。为了理解原因，让我们想想岩石。

想象一下，你的工作是搬运岩石，你有三堆不同大小的岩石。第一堆是小石子：非常轻，不大于你的拇指。第二堆是鹅卵石：重但足够轻便拾起，不大于你的头。第三堆是巨石：太大太重，无法抬起；你需要杠杆或机器来移动它们。你的任务是将一堆从山脚移到山顶（无论为何；但如果有帮助的话，可以想象你是西西弗斯）。你会选择哪一堆？

我假设你会选择小石子，因为它们轻而容易搬动。但有一个关键的细节可能会改变你的决定：重量。小石子堆重两公吨（相当于中型 SUV 的重量）。鹅卵石堆重一公吨（相当于一个非常小的汽车的重量）。而只有一个巨石，重半公吨（相当于十个成年人的重量）。现在你会选择哪一堆？

一方面，小石子要移动起来简单得多。你可以用铲子铲进推车里，然后推上山。只是小石子多（不是推车多）。大石头重量比较小，但是由于其独特的大小使其难以控制。需要特殊设备将其搬上山，但这只需完成一次任务。决定很难。第五章 提供了答案和解释，但在那章之前我们还有很多内容要覆盖。

数据类似于一堆岩石，执行查询类似于将岩石推上山。当数据量较小时，通常直接查询优化就足够了，因为数据很容易处理——就像手里拿着一把小石子走（或跑）上山。但随着数据量的增加，间接查询优化变得越来越重要——就像拖着一块重的鹅卵石爬山，并在半路上停下来问：“我们能做点什么处理这些岩石吗？”

第一章 提供了一个“证明”，即数据大小影响性能：`TRUNCATE TABLE` 显著提高性能，但不要使用这种“优化”。这是一个玩笑，但也证明了一个经常被忽视的观点：*数据越少性能越好*。这是一个口号；完整的陈述是：你可以通过减少数据来提高性能，因为较少的数据需要更少的系统资源（CPU、内存、存储等等）。

到目前为止，您可能已经发现本章将主张减少数据量。但是，*更多*数据不是驱使工程师学习性能优化的现实和理由吗？是的，第五章讨论了规模化的 MySQL，但首先必须学会在数据相对较小且问题可解时减少和优化数据。最紧张的学习时机是当您忽视数据大小直到它压垮应用程序时。

本章讨论数据与性能的关系，并主张减少数据访问和存储是一种技术——间接查询优化——以提高性能。有三个主要部分。第一部分揭示了 MySQL 性能的三个秘密。第二部分介绍了我所称的*最少数据原则*及其众多含义。第三部分介绍了如何快速且*安全*地删除或归档数据。

# 三个秘密

保守秘密是隐藏真相。以下真相在关于 MySQL 性能的书籍中并不总是透露出来，有两个原因。首先，它们使事情变得复杂。在不提及警告和注意事项的情况下写作和解释性能要容易得多。其次，它们是反直觉的。这并不意味着它们是错误的，但确实使它们难以澄清。尽管如此，以下真相对于 MySQL 性能至关重要，所以让我们以开放的心态深入探讨细节。

## 索引可能无法帮助

具有讽刺意味的是，您可以预期大多数慢查询使用索引查找。这有两个原因是讽刺的。首先，索引是性能的关键，但即使有很好的索引，查询也可能很慢。其次，在学习索引和索引技术之后（如第二章所讨论的），工程师变得擅长避免索引扫描和表扫描，只剩下索引查找，这是一个好问题，但仍然具有讽刺意味。

性能不可达到无索引，但这并不意味着索引为无限数据大小提供无限杠杆。不要对索引失去信心，但要注意以下情况，索引可能无法帮助。对于每种情况，假设查询及其索引无法进一步优化，则下一步是间接查询优化。

### 索引扫描

随着表的增长，索引扫描提供的杠杆减少，因为索引也增长：表行数越多，索引值也越多。^(1)（相比之下，只要索引适合内存，索引查找提供的杠杆几乎永远不会减少。）即使仅索引扫描通常也不会扩展，因为它几乎肯定会读取大量值——这是一个安全的假设，因为如果可能的话，MySQL 会进行索引查找以读取较少行。索引扫描只会推迟必然发生的事情：随着表中行数的增加，使用索引扫描的查询的响应时间也会增加。

### 查找行

当我优化使用索引查找的慢查询时，我首先检查的是行数（查看“行数检查”）。查找匹配行是查询的基本目的，但即使使用了良好的索引，查询也可能检查过多行。*太多*是响应时间变得不可接受的点（而根本原因不是其他因素，比如内存不足或磁盘 IOPS 不足）。这是因为几种索引查找访问类型可以匹配许多行。只有表 3-1 中列出的访问类型匹配*最多*一行。

表 3-1\. 匹配最多一行的索引查找访问类型

| ☐ | `system` |
| --- | --- |
| ☐ | `const` |
| ☐ | `eq_ref` |
| ☐ | `unique_subquery` |

如果 EXPLAIN 计划中的`type`字段不是表 3-1 中列出的访问类型之一，则要密切关注`rows`字段和查询指标行数检查（查看“行数检查”）。检查非常多的行无论索引查找如何都很慢。

###### 注意

[“EXPLAIN 输出格式”](https://oreil.ly/8dkRy)在 MySQL 手册中列出了访问类型，它称之为*连接类型*，因为 MySQL 将每个查询视为连接。在本书中，为了精确性和一致性，我只使用两个术语：*访问方法*和*访问类型*，如第 2 章中所述。

非常低的索引选择性很可能是一个罪魁祸首。回想一下“极端选择性”：索引选择性是基数除以表中的行数。MySQL 不太可能选择具有非常低选择性的索引，因为它可以匹配太多行。由于次要索引需要在主键中进行第二次查找以读取行，所以放弃具有极低选择性的索引并进行全表扫描可能更快——假设没有更好的索引。在 EXPLAIN 计划中，如果访问方法是表扫描（`type: ALL`），但存在 MySQL 可以使用的索引（`possible_keys`），则可以检测到这一点。要查看 MySQL 未选择的执行计划，请使用[`FORCE INDEX`](https://oreil.ly/nv1uy)强制使用`possible_keys`字段中列出的索引。最有可能的执行计划将是索引扫描（`type: index`），其中有大量的`rows`，这就是 MySQL 选择表扫描的原因。

###### 提示

回想一下“陷阱！（当 MySQL 选择其他索引时）”：在非常罕见的情况下，MySQL 会选择错误的索引。如果查询检查了太多行，但您确信有一个更好的索引 MySQL 应该使用，那么索引统计可能有误的可能性很小，这导致 MySQL 不选择更好的索引。运行`ANALYZE TABLE`来更新索引统计信息。

记住，索引选择性是基于基数和表中行数的函数。如果基数保持不变但行数增加，则选择性会降低。因此，在表很小时有帮助的索引，在表很大时可能无济于事。

### 连接表

当连接表时，每个表中的少数几行很快就会影响性能。如果您回忆起 “表连接算法”，嵌套循环连接（NLJ）算法（示例 2-22）意味着连接访问的总行数是每个表访问的行数的乘积。换句话说，在 EXPLAIN 计划中将`rows`的值相乘。一个每个表只有一百行的三表连接可以访问一百万行：100 × 100 × 100 = 1,000,000。为了避免这种情况，每个表连接的索引查找应该只匹配一行——在 表 3-1 中列出的访问类型之一是最佳选择。

MySQL 几乎可以按任何顺序连接表。利用这一点：有时解决不良连接的方案是在另一张表上创建更好的索引，以便 MySQL 改变连接顺序。

没有索引查找，表连接注定失败。结果是全连接，如 “选择全连接” 中预示的那样。但即使有索引，如果索引与单行不匹配，表连接也会遇到困难。

### 工作集大小

只有当索引在内存中时才有用。如果查询查找的索引值不在内存中，则 MySQL 会从磁盘读取它们。（更准确地说，构成索引的 B 树节点存储在 16KB 页中，MySQL 根据需要在内存和磁盘之间交换页面。）从磁盘读取比从内存读取慢几个数量级，这是一个问题，但主要问题是索引竞争内存。

如果内存有限但索引数众多且频繁用于查找大比例的值（相对于表大小），则索引使用可能会增加存储 I/O，因为 MySQL 试图保持频繁使用的索引值在内存中。这种情况可能发生，但很少，有两个原因。首先，MySQL 非常擅长保持频繁使用的索引值在内存中。其次，频繁使用的索引值及其引用的主键行被称为*工作集*，通常只占表大小的一小部分。例如，数据库可能有 500GB 大小，但应用程序经常只访问 1GB 的数据。考虑到这一事实，MySQL DBA 通常仅为总数据大小的 10%分配内存，通常舍入到标准内存值（64GB、128GB 等）。500GB 的 10%为 50GB，因此 DBA 可能会谨慎地舍入到 64GB 的内存。这种方法效果非常好，是一个很好的起点。

###### 提示

作为起点，为总数据大小分配 10%的内存。工作集大小通常只占总数据大小的一小部分。

当工作集大小显著大于可用内存时，索引可能没有帮助。相反，就像一团炽热的火焰，水不是灭火剂，索引使用会对存储 I/O 施加压力，使一切变慢。更多内存是一个快速解决方案，但请记住 “更好、更快的硬件！”：扩展不是一种可持续的方法。最佳解决方案是解决导致大工作集的数据大小和访问模式。如果应用程序确实需要存储和访问如此多的数据，以至于工作集大小无法在单个 MySQL 实例的合理内存量内容纳，那么解决方案是分片，详见第五章。

## 数据越少越好

经验丰富的工程师不会为一个巨大的数据库而欢呼，他们应对它。当数据大小显著减少时，他们会庆祝，因为数据越少越好。对什么好？一切：性能、管理、成本等等。处理 100 GB 的数据比在单个 MySQL 实例上处理 100 *TB* 要快得多、更容易、更便宜。前者如此之小，以至于智能手机都能处理。后者则需要专门处理：优化性能更具挑战性，管理数据可能存在风险（备份和恢复时间是多少？），找到价格合理的硬件为 100 TB 数据难度很大。保持数据大小合理比应对一个巨大的数据库更容易。

任何真正需要的数据都值得优化和管理。问题不在于数据大小，而在于无节制的数据增长。工程师们经常囤积数据：存储所有可能的数据。如果你在想，“不是我。我不会囤积数据”，那太好了。但你的同事可能不具备你令人称赞的数据苦行僧精神。如果是这样，在数据大小成为问题之前，提出无节制的数据增长的问题。

###### 提示

不要让一个难以管理的数据库令你措手不及。监控数据大小（参见 “数据大小”），并根据当前的增长率，估计未来四年的数据大小。如果未来的数据大小在当前硬件和应用设计下不可行，则在问题变成问题之前解决这个问题。

## QPS 越少越好

也许你永远找不到另一本书或者工程师会说*更低的* QPS 更好。珍惜这一刻。

我意识到这个秘密是反直觉的，甚至可能不受欢迎。要看到它的真理和智慧，考虑三个关于 QPS 较少争议的观点：

*QPS 只是一个数字——原始吞吐量的测量*。

它并未揭示任何关于查询或总体性能的定性内容。一个应用程序在 10,000 QPS 时可以有效处于空闲状态，而另一个在半数吞吐量时可能过载并处于宕机状态。即使在相同的 QPS 下，也存在许多定性差异。在 1,000 QPS 下执行`SELECT 1`几乎不需要系统资源，但在同样的 QPS 下执行复杂查询可能会对所有系统资源造成很大压力。而且无论 QPS 有多高，其也只有查询响应时间那么好。

*QPS 值没有客观意义*

它们既不好也不坏，既不高也不低，既不典型也不非典型。QPS 值只有与一个应用程序相关时才有意义。如果一个应用程序平均每秒 2,000 次请求，则 100 次请求可能意味着宕机。但是，如果另一个应用程序平均每秒 300 次请求，则 100 次请求可能是正常波动。QPS 还可以与外部事件相关：一天中的时间、一周中的日期、季节、假期等等。

*增加 QPS 是困难的*

相比之下，数据大小可以相对容易地从 1 GB 增加到 100 GB——增加了 100 倍。但是，增加 QPS 100 倍（除了极低的值，如从 1 QPS 到 100 QPS）却非常困难。即使是 QPS 的 2 倍增加也可能非常具有挑战性。相对于应用程序的最大 QPS 增加更具挑战性，因为您无法购买更多的 QPS，而存储和内存则不同。

总结这些观点：QPS 不是定性的，只是相对于一个应用程序，而且难以增加。具体说来：*QPS 对你没有帮助*。它更像是一种负担而非资产。因此，更少的 QPS 才更好。

经验丰富的工程师们在 QPS 减少（有意）时庆祝，因为较少的 QPS 意味着更多的增长空间。

# 最少数据原则

我将最少数据原则定义为：*仅存储和访问所需的数据*。这在理论上听起来显而易见，但在实践中远非常态。这也是为何接下来的两个部分有许多细节之处的原因。

> 常识并不常见。
> 
> 伏尔泰

## 数据访问

不要访问比所需更多的数据。*访问*指的是 MySQL 执行查询时的所有工作：查找匹配行、处理匹配行，并返回结果集，无论是读取（`SELECT`）还是写入。高效的数据访问尤为重要，因为增加写入的规模更为困难。

表 3-2 是一个清单，你可以应用于每一个查询——希望是每一个查询——以验证其数据访问效率。

表 3-2\. 高效数据访问检查清单

| ☐ | 仅返回必要的列 |
| --- | --- |
| ☐ | 减少查询复杂性 |
| ☐ | 限制行访问 |
| ☐ | 限制结果集 |
| ☐ | 避免对行进行排序 |

公平和平衡地说，忽略单个检查项不太可能影响性能。例如，第五条项目——避免对行进行排序——通常会被忽略，而不会影响性能。这些项目是最佳实践。如果你实践它们直到变成习惯，你将比完全忽略它们的工程师取得更大的成功和 MySQL 的性能。

在我解释表 3-2 中的每一项之前，让我们花一段时间来重新讨论一个在第一章中推迟到这一章的例子。

或许你还记得“查询概要”中的这个例子：“在我写这篇文章的时候，我正在查看一个查询负载为 5,962 的查询。这是怎么可能的？”这种查询负载之所以可能，归功于*极其*高效的数据访问和一个非常忙碌的应用程序。这个查询类似于`SELECT col1, col2 WHERE pk_col = 5`：一个主键查找，只返回单行的两列。当数据访问如此高效时，MySQL 函数*几乎*像是一个内存缓存，并以令人难以置信的 QPS 和查询负载执行查询。*几乎*，但不完全是，因为每个查询都是一个包含开销的事务。（第八章专注于事务。）要优化这样的查询，你必须改变访问模式，因为查询不能进一步优化，数据大小也不能减少。我在第四章中再次讨论这个查询。

### 只返回所需列

查询应该只返回所需的列。

不要使用`SELECT *`。如果表中有任何`BLOB`、`TEXT`或`JSON`列，这一点尤为重要。

你可能之前听过这个最佳实践，因为数据库行业（不仅仅是 MySQL）已经在强调这一点数十年了。我想不起最后一次在生产环境中看到`SELECT *`了，但这一点非常重要，所以不断重复是必要的。

### 减少查询复杂性

查询应尽可能简单。

*查询复杂性*指的是构成查询的所有表、条件和 SQL 子句。在这个上下文中，复杂性只相对于一个查询而言，而不是工程师。查询`SELECT col FROM tbl WHERE id = 1`比一个涉及五个表和许多`WHERE`条件的查询更简单。

复杂的查询是工程师的问题，而不是 MySQL 的问题。查询越复杂，分析和优化就越困难。如果你幸运的话，一个复杂的查询可能运行良好，从不出现作为慢查询的情况（参见“查询概要”）。但幸运不是最佳实践。从一开始（首次编写时）保持查询简单，并在可能时减少查询复杂性。

关于数据访问，简单查询倾向于访问较少的数据，因为它们有较少的表、条件和 SQL 子句——MySQL 的工作量更少。但要小心：错误的简化可能会产生更糟的 EXPLAIN 计划。例如，第 2 章 中的 图 2-21 展示了删除条件如何取消 `ORDER BY` 优化，导致（稍微）更差的 EXPLAIN 计划。始终确认简化的查询是否具有等效或更好的 EXPLAIN 计划，以及相同的结果集。

### 限制行访问

查询应尽可能访问尽少的行。

访问太多行通常会令人惊讶；这不是工程师有意为之的事情。随着时间的推移，数据的增长是一个常见的原因：一个快速查询开始时只访问几行，但几年后和几千兆字节后，它变成了一个慢查询，因为它访问了太多行。简单的错误是另一个原因：工程师编写了一个他们认为会访问少数行的查询，但他们错了。在数据增长和简单错误的交汇处是最重要的原因：*不限制范围和列表*。像 `col > 75` 这样的无限范围如果 MySQL 在 `col` 上进行范围扫描，可以访问无数行。即使这是有意为之的，因为假定表很小，请注意随着表的增长，行访问几乎没有界限，特别是如果 `col` 上的索引是非唯一的。

`LIMIT` 子句并不限制行访问，因为 `LIMIT` 适用于匹配行后的结果集。唯一的例外是 `ORDER BY`…`LIMIT` 优化：如果 MySQL 可以按索引顺序访问行，则当找到 `LIMIT` 数量的匹配行时，它会停止读取行。但有趣的是：`EXPLAIN` 不会报告是否使用了此优化。您必须从 `EXPLAIN` 报告的内容和未报告的内容推断出是否使用了该优化。让我们花点时间看看这个优化是如何起作用的，并证明它限制了行访问。

使用表 `elem`（示例 2-1）来自第 2 章，让我们首先执行一个没有 `LIMIT` 子句的查询。示例 3-1 显示该查询返回了八行。

##### 示例 3-1\. 没有 `LIMIT` 的查询行

```
SELECT * FROM elem WHERE a > 'Ag' ORDER BY a;

+----+----+----+----+
| id | a  | b  | c  |
+----+----+----+----+
|  8 | Al | B  | Cd |
|  9 | Al | B  | Cd |
|  3 | Al | Br | Cr |
| 10 | Ar | B  | Cd |
|  4 | Ar | Br | Cd |
|  5 | Ar | Br | C  |
|  7 | At | Bi | Ce |
|  2 | Au | Be | Co |
+----+----+----+----+
8 rows in set (0.00 sec)
```

没有 `LIMIT` 子句，该查询访问（并返回）了八行。因此，即使有 `LIMIT 2` 子句，`EXPLAIN` 报告的是 `rows: 8`，正如 示例 3-2 中所示，因为 MySQL 无法知道在执行查询之前有多少行在范围内*不*匹配。最糟糕的情况是 MySQL 读取所有行，因为没有一行匹配。但对于这个简单的示例，我们可以看到前两行（`id` 值为 8 和 9）将匹配唯一的表条件。如果我们是正确的，查询指标将报告检查了两行，而不是八行。但首先，让我们看看如何从 示例 3-2 的 EXPLAIN 计划中推断出这种优化。

##### 示例 3-2\. `ORDER BY`…`LIMIT` 优化的 EXPLAIN 计划

```
EXPLAIN SELECT * FROM elem WHERE a > 'Ag' ORDER BY a LIMIT 2\G

*************************** 1\. row ***************************
           id: 1
  select_type: SIMPLE
        table: elem
   partitions: NULL
         type: range
possible_keys: a
          key: a
      key_len: 8
          ref: NULL
         rows: 8
     filtered: 100.00
        Extra: Using index condition
```

你可以推断 MySQL 使用了`ORDER BY`…`LIMIT`优化来访问仅两行（`LIMIT 2`），因为：

+   查询使用了一个索引（`type: range`）

+   `ORDER BY`列是该索引的最左前缀（`key: a`）

+   `Extra`字段并*不*报告“使用文件排序”。

证据显示在示例 3-3 中：MySQL 执行查询后的慢查询日志片段。

##### 示例 3-3。`ORDER BY`…`LIMIT`优化的查询指标

```
# Query_time: 0.000273  Lock_time: 0.000114  Rows_sent: 2  Rows_examined: 2
SELECT * FROM elem WHERE a > 'Ag' ORDER BY a LIMIT 2;
```

在第一行末尾的`Rows_examined: 2`证明了 MySQL 使用了`ORDER BY`…`LIMIT`优化，仅访问了两行而不是所有八行。要了解更多关于这种查询优化的信息，请阅读 MySQL 手册中的[“LIMIT 查询优化”](https://oreil.ly/AnurD)。

关于限制范围和列表，有一个重要因素需要验证：*应用程序是否限制了查询中使用的输入？* 早在“平均值、百分位数和最大值”中，我讲述了一个故事：“长话短说，这个查询用于查找欺诈检测数据，有时一个大案例会一次查找几千行，这导致 MySQL 切换查询执行计划。” 在那种情况下，解决方案很简单：每个请求限制应用程序输入至一千个值。该案例还突显了一个事实：人类可以输入大量值。通常情况下，工程师在用户是另一个计算机时会小心限制输入，但当用户是另一个人类时，他们的警惕性会放松，因为他们认为人类不会或不能输入太多值。但他们错了：通过复制粘贴和迫在眉睫的截止日期，普通人可以使任何计算机超负荷运行。

对于写入操作，限制行访问至关重要，因为通常情况下，InnoDB 在更新匹配行之前会锁定它访问的每一行。因此，InnoDB 可能会锁定比您预期更多的行。“行锁定”对此进行了详细说明。

对于表连接，限制行访问同样至关重要：回想一下从“连接表”中得知，对每个表进行连接时，少量行很快就会导致性能严重下降。在那一节中，我指出如果没有索引查找，表连接注定会失败。在这一节中，我要指出，除非也访问了非常少的行，否则表连接也注定会失败。记住：在非唯一索引上的索引查找可以访问任意数量的重复行。

了解您的访问模式：对于每个查询，限制行访问是什么？使用`EXPLAIN`查看预估行访问（`rows`字段），并监视检查的行数（参见“检查的行数”），以避免访问过多行的意外情况。

### 限制结果集

查询应尽可能返回尽少的行。

这比在查询上放置`LIMIT`子句更为复杂，尽管这确实有帮助。它指的是应用程序不使用整个*结果集*：查询返回的行。这个问题有三种变化。

第一种变体发生在应用程序使用了一些行，但并非全部。这可能是有意或无意的。无意中，它表明`WHERE`子句需要更好（或更多）的条件才能匹配仅需要的行。您可以在过滤行而不是使用`WHERE`条件的应用程序代码中发现这一点。如果发现了这种情况，请与您的团队讨论以确保这不是有意的。有意地，应用程序可能选择更多的行以避免通过将行匹配从 MySQL 转移到应用程序来复杂化查询。这种技术仅在减少响应时间时才有用，类似于 MySQL 在少数情况下选择表扫描。

第二种变体发生在查询具有`ORDER BY`子句且应用程序使用有序的行子集时。行的顺序对第一种变体并不重要，但对第二种变体却是定义性特征。例如，一个查询返回 1000 行，但应用程序只按顺序使用前 20 行。在这种情况下，解决方案可能很简单，只需在查询中添加`LIMIT 20`子句。

应用程序对剩余的 980 行做了什么？如果这些行从未被使用过，那么查询肯定不应该返回它们——请添加`LIMIT 20`子句。但是如果这些行被使用了，那么应用程序很可能在进行分页：每次使用 20 行（例如，每页显示 20 个结果）。在这种情况下，使用`LIMIT 20 OFFSET N`按需获取页面可能更快、更高效——其中 N = 20 ×（页码 - 1）——前提是可以使用`ORDER BY`...`LIMIT`优化（请参见前一节，“限制行访问”）。这种优化是必需的，因为如果没有它，MySQL 必须在应用`LIMIT`子句的`OFFSET`部分之前找到并排序所有匹配行——这会浪费大量工作，只为返回 20 行。但即使没有这种优化，也有另一个解决方案：一个大但合理的`LIMIT`子句。例如，如果您测量应用程序的使用情况并发现大多数请求只使用前五页，则使用`LIMIT 100`子句获取前五页并为大多数请求减少结果集大小 90%。

第三种变体发生在应用程序*仅*聚合结果集时。如果应用程序聚合结果集*并*使用单独的行，则是可以接受的。反模式是*仅*聚合结果集而不使用 SQL 聚合函数，这会限制结果集。表 3-3 列出了四种反模式及其相应的 SQL 解决方案。

表 3-3\. 应用程序中的四种结果集反模式

| 应用程序中的反模式 | SQL 中的解决方案 |
| --- | --- |
| 添加列值 | `SUM(column)` |
| 计算行数 | `COUNT(*)` |
| 计算值的数量 | `COUNT(column)`…`GROUP BY column` |
| 计算不同值的数量 | `COUNT(DISTINCT column)` |
| 提取不同的值 | `DISTINCT` |

添加列值适用于其他统计函数：`AVG()`、`MAX()`、`MIN()`等等。让 MySQL 进行计算，而不是返回行。

计算行数是一个极端的反模式，但我见过这种情况，所以我确信还有其他应用程序在不必要的行上悄悄浪费网络带宽。永远不要仅仅用于计数行数的应用程序；在查询中使用`COUNT(*)`。

###### 注意

截至 MySQL 8.0.14 版本，`SELECT COUNT(*) FROM table`（没有`WHERE`子句）使用多个线程并行读取主键。这不是并行查询执行；MySQL 手册称其为“并行聚簇索引读取”。

计算值的数量对程序员来说可能比在 SQL `GROUP BY`子句中表达更容易，但应该使用后者来限制结果集。再次使用表`elem`（示例 2-1），示例 3-4 演示了如何使用`COUNT(column)`…`GROUP BY column`来计算列的值的数量。

##### 示例 3-4\. 计算值的数量

```
SELECT a, COUNT(a) FROM elem GROUP BY a;

+----+----------+
| a  | COUNT(a) |
+----+----------+
| Ag |        2 |
| Al |        3 |
| Ar |        3 |
| At |        1 |
| Au |        1 |
+----+----------+
```

对于表`elem`中的列`a`，有两行的值为“Ag”，三行的值为“Al”，依此类推。SQL 解决方案返回五行，而反模式将返回所有十行。这些数字并不激增——五行与十行——但它们说明了一个观点：查询可以通过 SQL 聚合来限制其结果集，而不是通过应用程序代码。

提取不同的值——在应用程序中使用关联数组去重复列值很简单；但 MySQL 也可以通过`DISTINCT`来实现，这限制了结果集（`DISTINCT`因为是`GROUP BY`的特例而被视为聚合函数）。`DISTINCT`在处理单列时尤为清晰和有用。例如，`SELECT DISTINCT a FROM elem`返回列`a`的唯一值列表。（如果你好奇，列`a`有五个唯一值：“Ag”，“Al”，“Ar”，“At”和“Au”。）使用`DISTINCT`的一个注意事项是它适用于所有列。`SELECT DISTINCT a, b FROM elem`返回具有列`a`和`b`值的唯一*行*列表。想了解更多，请参阅 MySQL 手册中的[“DISTINCT 优化”](https://oreil.ly/j3IjK)。

### 避免对行进行排序。

查询应避免对行进行排序。

在应用程序中排序行而不是在 MySQL 中排序可以通过去除`ORDER BY`子句来减少查询复杂性，并通过将工作分配给应用程序实例来更好地扩展，后者比 MySQL 更容易扩展。

没有`LIMIT`子句的`ORDER BY`子句是可以去除的明显迹象，应用程序可以对行进行排序。（它可能也是前一节讨论的问题的第二个变体。）查找具有`ORDER BY`子句但没有`LIMIT`子句的查询，然后确定应用程序是否可以代替 MySQL 对行进行排序——答案应该是肯定的。

## 数据存储

不要存储比所需更多的数据。

尽管数据对你很有价值，但对 MySQL 来说是无用的。表格 3-4 是一个高效数据存储的检查清单。

我强烈建议您审查一下您的数据存储，因为惊喜很容易发现。我在第二章开头提到了一个这样的惊喜：我创建的应用程序意外地存储了一 *十亿* 行数据。

表格 3-4\. 高效数据存储检查清单

| ☐ | 仅存储所需的行 |
| --- | --- |
| ☐ | 每一列都被使用 |
| ☐ | 每一列都是紧凑和实用的 |
| ☐ | 每个值都是紧凑和实用的 |
| ☐ | 每个次要索引都被使用且不重复 |
| ☐ | 仅保留所需的行 |

如果您能勾选所有六个项目，那么您将非常适合将数据扩展到任何规模。但这并不容易：有些项目比实施更容易被忽略，特别是当数据库很小时。但不要拖延：发现和纠正存储效率低下的最佳时机是在数据库很小的时候。在规模化时，每秒钟和地球一天中的所有 86,400 秒乘以高吞吐量时，一个字节或两个字节可能会产生很大的差异。为规模设计，为成功计划。

### 仅存储所需的行

当应用程序发生变化和增长时，工程师可能会忘记它存储了什么。如果数据存储不是问题，工程师就没有理由查看或询问存储了什么。如果很长时间以来你或其他人都没有审查过应用程序存储的内容，或者你是团队或应用程序的新成员，那就来看看吧。例如，我曾见过，已经忘记的服务写入了（至少几年来）没有人在使用的数据。

### 每一列都被使用

比仅存储所需行更深入的是仅保留所需列。同样，随着应用程序的变化和增长，工程师可能会忘记列，特别是在使用对象关系映射（ORM）时。

不幸的是，MySQL 中没有工具或自动化方法来找出未使用的列。MySQL 跟踪哪些数据库、表和索引被使用，但它不跟踪列的使用情况。没有比未使用的列更隐秘的东西了。唯一的解决方案是手动审查：将应用程序查询使用的列与表中存在的列进行比较。

### 每一列都是紧凑和实用的

除了仅存储所需行之外，再深一层次的是使每一列都紧凑而实用。*紧凑* 意味着使用最小的数据类型来存储值。*实用* 意味着不要使用太小的数据类型，以至于对你或应用程序来说是繁琐或容易出错。例如，使用无符号的 `INT` 作为位域是紧凑的（没有比位更小的东西），但通常不实用。

###### 提示

熟悉所有[MySQL 数据类型](https://oreil.ly/x7fTF)。

经典反模式是数据类型`VARCHAR(255)`。这种特定的数据类型和大小是许多程序和工程师的常见但低效的默认选择，他们很可能是从另一个程序或工程师那里复制了这种做法。你会看到它被用来存储任何东西，这就是为什么它是低效的。

例如，让我们重用`elem`表（Example 2-1）。原子符号是一个或两个字符。列定义`atomic_symbol VARCHAR(255)`在技术上是紧凑的——`VARCHAR`是可变长度的，所以它只会使用一个或两个字符——但它允许*垃圾进、垃圾出*：无效值，比如“Carbon”而不是“C”，这可能对应用程序产生未知的后果。一个更好的列定义是`atomic_symbol CHAR(2)`，既紧凑又实用。

列定义`atomic_symbol ENUM(`…`)`在`elem`表中更好吗？`ENUM`比`CHAR(2)`更紧凑，但在超过一百个原子符号的情况下更实用吗？这是一个你可以决定的权衡；任何选择都显然比`VAR⁠CHAR(255)`更好。

###### 提示

[`ENUM`](https://oreil.ly/WMXfA)是高效数据存储中的一位默默无闻的英雄之一。

警惕列字符集。如果没有明确定义，它默认为表字符集，如果表字符集也没有明确定义，则默认为服务器字符集。截至 MySQL 8.0，默认服务器字符集为`utf8mb4`。对于 MySQL 5.7 及更早版本，默认服务器字符集为`latin1`。根据字符集，像*é*这样的单个字符可能存储为多个字节。例如，使用`latin1`字符集，MySQL 将*é*存储为一个字节：0xE9。但是使用`utf8mb4`字符集，MySQL 将*é*存储为两个字节：0xC3A9。（表情符号每个字符使用四个字节。）字符集是一个特殊且博学的领域，超出了大多数书籍的范围。现在，你需要知道的是：*一个字符*可能需要*多个字节*的存储空间，这取决于字符和字符集。在大表中，字节很快累积起来。

对于`BLOB`、`TEXT`和`JSON`数据类型要非常保守。不要将它们用作倾倒场所、万能容器或通用桶。例如，不要将图像存储在`BLOB`中——你可以这样做，它能工作，但最好不要。有远比这更好的解决方案，比如[Amazon S3](https://aws.amazon.com/s3)。

紧凑且实用一直延伸到位级别。另一个令人惊讶的常见但易于避免的列存储效率低下是浪费[整数数据类型](https://oreil.ly/6CdwC)的高阶位。例如，使用`INT`而不是`INT UNSIGNED`：最大值分别约为 20 亿和 40 亿。如果值不能为负数，则使用无符号数据类型。

###### 注意

截至 MySQL 8.0.17，`UNSIGNED`对于`FLOAT`、`DOUBLE`和`DECIMAL`数据类型已经不推荐使用。

在软件工程的世界中，像这样的细节可能被视为微优化或过早优化，这是不被赞同的，但在架构设计和数据库性能的世界中，它们是最佳实践。

### 每个值都是紧凑和实用的

比仅存储所需行更深一层次的是使每个值都紧凑和实用。*实用*的含义与前一节中定义的相同，但*紧凑*意味着值的最小表示。紧凑的值在应用程序如何使用它们方面具有很高的依赖性。例如，考虑一个具有一个前导空格和一个尾随空格的字符串：`“ and ”`。Table 3-5 列出了一个应用程序可以压缩此字符串的六种方式。

表 3-5。六种压缩字符串`“ and ”`的方式

| 紧凑值 | 可能的用途 |
| --- | --- |
| `“and”` | 去除所有空白。这在字符串中很常见。 |
| `“ and”` | 去除尾随空白。在许多语法中（如 YAML 和 Markdown），前导空格在语法上是重要的。 |
| `“and ”` | 去除前导空白。虽然较少见，但仍有可能。有时程序用于连接空格分隔的参数（如命令行参数）。 |
| `“”` | 删除该值（空字符串）。也许该值是可选的，如`FROM table AS table_alias`中的*AS*，可以写作`FROM table table_alias`。 |
| `“&”` | 用等效符号替换字符串。在书面语言中，和符号字符在语义上等同于单词“and”。 |
| `NULL` | 无值。也许该值完全是多余的，可以删除，结果是没有值（甚至不是空字符串，技术上也是一个值）。 |

Table 3-5 中的转换代表了压缩值的三种方式：最小化、编码和去重。

#### 最小化

要最小化一个值，需要删除多余和无用的数据：空白、注释、头部等等。让我们考虑在 Example 3-5 中更为复杂而又熟悉的值。

##### Example 3-5。格式化的 SQL 语句（未经最小化处理）

```
SELECT
  /*!40001 SQL_NO_CACHE */
  col1,
  col2
FROM
  tbl1
WHERE
  /* comment 1 */
  foo = ' bar '
ORDER BY col1
LIMIT 1; — comment 2
```

如果一个应用程序仅存储 Example 3-5 中 SQL 语句的功能部分，那么它可以通过折叠关键字之间的空白（而不是值内部的空白）并删除最后两个注释（而不是第一个）来最小化值。Example 3-6 是最小化（紧凑）值。

##### Example 3-6。最小化的 SQL 语句

```
SELECT /*!40001 SQL_NO_CACHE */ col1, col2 FROM tbl1 WHERE foo=' bar ' LIMIT 1
```

示例 3-5 和 3-6 在功能上是等效的（相同的 EXPLAIN 计划），但最小化值的数据大小几乎减少了*50%*（48.9%）：分别从 137 字节减少到 70 字节。对于长期数据增长来说，50%的减少——甚至只有 25%——都是显著且有影响力的。

SQL 语句的最小化说明了一个重要观点：最小化一个值并不总是简单的。SQL 语句不是毫无意义的字符串：它是一种需要语法意识正确最小化的语法。第一个注释不能删除，因为它是功能性的（参见 MySQL 手册中的 [“Comments”](https://oreil.ly/3l8zy)）。同样，引号值 `' bar '` 中的空格是有功能性的：`' bar '` 不等于 `'bar'`。而且你可能已经注意到一个细节：末尾的分号被移除了，因为在这个上下文中它没有功能性，但在其他上下文中它是有功能性的。

在考虑如何最小化一个值时，首先要考虑其数据格式。数据格式的语法和语义决定了哪些数据是多余和不必要的。例如，在 YAML 中，像 `# like this` 的注释是纯粹的注释（不像某些 SQL 注释），如果应用程序不需要它们，可以删除它们。即使您的数据格式是定制的，它也必须具有一些语法和语义，否则应用程序无法以编程方式读取和写入它。了解数据格式以正确最小化一个值是必要的。

最小的值是没有值：`NULL`。我知道处理 `NULL` 可能是个挑战，但有一个优雅的解决方案，强烈建议您使用：[`COALESCE()`](https://oreil.ly/muYZW)。例如，如果 `middle_name` 列是可空的（不是所有人都有中间名），则使用 `COALESCE(middle_name, '')` 来返回设置的值，否则返回空字符串。这样，您可以享受 `NULL` 存储的好处——只需一个比特——而无需在应用程序中处理空字符串（或指针）。在实际情况下，使用 `NULL` 而不是空字符串、零值和魔法值需要一些额外的工作，但这是最佳实践。

###### 警告

`NULL` 和 `NULL` 是唯一的；也就是说，两个空值是唯一的。避免在可空列上使用唯一索引，或确保应用程序正确处理带有 `NULL` 值的重复行。

如果您确实想避免使用 `NULL`，上述警告是您的技术原因。这两组值是*唯一*的：`(1, NULL)` 和 `(1, NULL)`。这不是打印错误。对于人类来说，这些值看起来是相同的，但对于 MySQL 来说它们是唯一的，因为 `NULL` 与 `NULL` 的比较是未定义的。请查看 MySQL 手册中的 [“Working with NULL Values”](https://oreil.ly/oyTPZ)。它以一种谦逊的承认开始：“直到你习惯了它，`NULL` 的值可能会让人惊讶。”

#### 编码

要对值进行编码，将其从人类可读转换为机器编码。数据可以编码并以一种方式存储在计算机中，以另一种方式解码并显示给人类。在计算机上存储数据的最有效方法是为计算机编码它。

###### 提示

为机器存储，为人类显示。

典型的示例和反模式是将 IP 地址存储为字符串。例如，将`127.0.0.1`作为字符串存储在`CHAR(15)`列中。 IP 地址是四字节无符号整数，这是真正的机器编码。（如果您感兴趣，`127.0.0.1`是十进制值 2130706433。）要编码和存储 IP 地址，请使用数据类型`INT UNSIGNED`和函数`INET_ATON()`和`INET_NTOA()`分别进行字符串转换。如果编码 IP 地址不切实际，则数据类型`CHAR(15)`是可接受的替代方案。

另一个类似的示例和反模式是将 UUID 存储为字符串。 UUID 是表示为字符串的多字节整数。由于 UUID 的字节长度不同，您需要使用数据类型`BINARY(N)`，其中`N`是字节长度，并使用函数`HEX()`和`UNHEX()`来转换值。或者，如果您使用的是 MySQL 8.0（或更新版本）和 RFC 4122 UUID（MySQL `UUID()`生成的），则可以使用函数`UUID_TO_BIN()`和`BIN_TO_UUID()`。如果编码 UUID 不切实际，至少使用数据类型`CHAR(N)`存储字符串表示，其中`N`是字符长度。

存储数据的更紧凑的计算机编码方法是压缩。但这是一种极端方法，涉及到空间和速度权衡的灰色区域，这超出了本书的范围。我还没有看到需要性能或规模化的情况下使用压缩的案例。高效数据存储检查表（表 3-4）的严格应用使数据扩展到如此之大，以至于其他问题变成阻碍：备份和恢复时间等。如果您认为需要压缩以提高性能，请咨询专家以验证。

顺便说一下编码的问题，有一个重要的最佳实践，我会插入到这一节中：只将日期和时间存储为 UTC。仅在显示（或打印）时将日期和时间转换为本地时间（或适当的时区）。还要注意，MySQL 的`TIMESTAMP`数据类型将在 2038 年 1 月 19 日结束。如果您在 2037 年 12 月收到这本书作为节日礼物，并且您的数据库有`TIMESTAMP`列，您可能希望稍早些回到工作。

#### 重复项去除

要去重值，请将列规范化为另一个具有一对一关系的表。这种方法完全是应用程序特定的，因此让我们考虑一个具体的例子。想象一个过于简单的书籍目录，存储在仅有两列`title`和`genre`的表中。（让我们关注数据，忽略数据类型和索引等细节。）示例 3-7 显示了一个包含五本书和三个唯一流派的表。

##### 示例 3-7\. 具有重复`genre`值的图书目录

```
+--------------------------------+-----------+
| title                          | genre     |
+--------------------------------+-----------+
| Efficient MySQL Performance    | computers |
| TCP/IP Illustrated             | computers |
| The C Programming Language     | computers |
| Illuminations                  | poetry    |
| A Little History of the World  | history   |
+--------------------------------+-----------+
```

列`genre`具有重复值：三个`computers`值的实例。为了去重，将该列规范化到另一个具有一对一关系的表中。示例 3-8 展示了顶部的新表和底部修改后的原始表。这两个表在列`genre_id`上有一对一的关系。

##### 示例 3-8\. 规范化的书目目录

```
+----------+-----------+
| genre_id | genre     |
+----------+-----------+
|        1 | computers |
|        2 | poetry    |
|        3 | history   |
+----------+-----------+

+--------------------------------+-----------+
| title                          | genre_id  |
+--------------------------------+-----------+
| Efficient MySQL Performance    | 1         |
| TCP/IP Illustrated             | 1         |
| The C Programming Language     | 1         |
| Illuminations                  | 2         |
| A Little History of the World  | 3         |
+--------------------------------+-----------+
```

原始表（底部）仍然具有列`genre_id`的重复值，但在规模上数据尺寸大大减少。例如，“computers”字符串需要 9 个字节存储，而使用`SMALLINT UNSIGNED`数据类型只需要 2 个字节存储整数 1，允许有 65,536 个唯一的流派（可能足够）。这是数据尺寸减少了 77.7%：从 9 个字节到 2 个字节。

以这种方式去重值通过*数据库规范化*完成：根据逻辑关系（一对一、一对多等）将数据分成表。然而，去重数据并不是数据库规范化的目标或目的。

###### 注意

数据库规范化超出了本书的范围，因此我不会进一步解释它。关于这个主题有许多书籍，因此你不会有任何麻烦找到一本很好的书来学习数据库规范化。

从这个例子可以看出，数据库规范化*导致*值的去重，但这并不完全正确。示例 3-7 中的单个表在技术上是第一、第二和第三正规形式（假设有主键）—完全规范化，只是设计不良。更准确地说，去重值是数据库规范化的常见（且期望的）副作用。而且由于你应该在任何情况下都对数据库进行规范化，因此你可能会避免重复值。

这里有一个有趣的反面：*反规范化*。反规范化是规范化的反面：将相关数据组合到一个表中。示例 3-7 中的单个表可能是一个反规范化表，如果这是其设计的意图的话。反规范化是一种通过消除表连接和相关复杂性来提高性能的技术。但不要急于反规范化你的模式，因为这涉及到超出本书范围的细节和权衡。实际上，反规范化是*更多数据*的相反，因为它有意地复制数据以换取速度。

###### 提示

安全和最佳实践是数据库规范化和减少数据。使用这两者可以实现令人难以置信的规模和性能。

### 每个二级索引都被使用且不重复。

在高效数据存储检查表 (Table 3-4) 中倒数第二：每个次要索引都在使用且不是重复的。避免未使用的索引和重复的索引始终是一个好主意，但对于数据大小尤为重要，因为索引是数据的副本。确实，次要索引比完整表（主键）要小得多，因为它们只包含索引列值和相应的主键列值，但随着表的增长，这些会累积。

放弃未使用和重复的次要索引是减少数据大小的简单方法，但要小心。如 “Excessive, Duplicate, and Unused” 中所述，查找未使用的索引很棘手，因为某个索引可能不经常使用，因此务必检查足够长的时间段内的索引使用情况。相比之下，重复索引更容易找到：使用 [pt-duplicate-key-checker](https://oreil.ly/qSStI)。再次强调：删除索引时要小心。

放弃索引只能恢复与索引大小相等的数据大小。有三种方法可以查看索引大小。让我们使用 [`employees` sample database](https://oreil.ly/lwWxR)，因为它有几兆字节的索引数据。查看索引大小的首选方法是查询表 `INFORMATION_SCHEMA.TABLES`，如 Example 3-9 所示。

##### 示例 3-9\. 员工示例数据库的索引大小 (`INFORMATION_SCHEMA`)

```
SELECT
  TABLE_NAME, DATA_LENGTH, INDEX_LENGTH
FROM
  INFORMATION_SCHEMA.TABLES
WHERE
  TABLE_TYPE = 'BASE TABLE' AND TABLE_SCHEMA = 'employees';

+--------------+-------------+--------------+
| TABLE_NAME   | DATA_LENGTH | INDEX_LENGTH |
+--------------+-------------+--------------+
| departments  |       16384 |        16384 |
| dept_emp     |    12075008 |      5783552 |
| dept_manager |       16384 |        16384 |
| employees    |    15220736 |            0 |
| salaries     |   100270080 |            0 |
| titles       |    20512768 |            0 |
+--------------+-------------+--------------+
```

`TABLE_NAME` 是 `employees` 示例数据库中的表名——仅有六个表。（该数据库有一些视图，根据条件 `TABLE_TYPE = 'BASE TABLE'` 进行了过滤。）`DATA_LENGTH` 是主键的大小（以字节为单位）。`INDEX_LENGTH` 是所有次要索引的大小（以字节为单位）。最后四个表没有次要索引，只有一个主键。

查看索引大小的第二种历史（但仍广泛使用）方法是 `SHOW TABLES STATUS`。您可以添加一个 `LIKE` 子句，仅显示一个表，如 Example 3-10 所示。

##### 示例 3-10\. 表 `employees.dept_emp` 的索引大小 (`SHOW TABLE STATUS`)

```
SHOW TABLE STATUS LIKE 'dept_emp'\G

*************************** 1\. row ***************************
           Name: dept_emp
         Engine: InnoDB
        Version: 10
     Row_format: Dynamic
           Rows: 331143
 Avg_row_length: 36
    Data_length: 12075008
Max_data_length: 0
   Index_length: 5783552
      Data_free: 4194304
 Auto_increment: NULL
    Create_time: 2021-03-28 11:15:15
    Update_time: 2021-03-28 11:15:24
     Check_time: NULL
      Collation: utf8mb4_0900_ai_ci
       Checksum: NULL
 Create_options:
        Comment:
```

`SHOW TABLE STATUS` 输出中的 `Data_length` 和 `Index_length` 字段与 `INFORMATION_SCHEMA.TABLES` 中的相同列和值。最好查询 `INFORMATION_SCHEMA.TABLES`，因为您可以在 `SELECT` 子句中使用函数，例如 `ROUND(DATA_LENGTH / 1024 / 1024)` 将字节转换并四舍五入为其他单位的值。

查看索引大小的第三种方法目前是唯一的方法：查询表 `mysql.innodb_index_stats`，如 Example 3-11 中显示的 `employees.dept_emp` 表。

##### 示例 3-11\. 表 `employees.dept_emp` 上每个索引的大小 (`mysql.innodb_index_stats`)

```
SELECT
  index_name, SUM(stat_value) * @@innodb_page_size size
FROM
  mysql.innodb_index_stats
WHERE
      stat_name = 'size'
  AND database_name = 'employees'
  AND table_name = 'dept_emp'
GROUP BY index_name;

+------------+----------+
| index_name | size     |
+------------+----------+
| PRIMARY    | 12075008 |
| dept_no    |  5783552 |
+------------+----------+
```

表 `employees.dept_emp` 有两个索引：一个主键和一个名为 `dept_no` 的次要索引。`size` 列包含每个索引的大小（以字节为单位），实际上是索引页数乘以 InnoDB 页大小（默认为 16 KB）。

`employees` 示例数据库并不是次级索引大小的壮观展示，但现实世界的数据库可能会因大量次级索引而溢出，这些次级索引占据了总数据大小的相当部分。定期检查索引使用情况和索引大小，并通过仔细删除未使用的和重复的索引来减少总数据大小。

### 只保留所需行

效率数据存储清单的最后一项（表 3-4）：只保留所需行。这一项将我们带回全循环，与第一项闭环：“只存储所需行”。存储时可能需要一行，但这种需求随时间变化而变化。删除（或归档）不再需要的行。听起来很明显，但通常会发现包含遗忘或被弃用数据的表格。我已经不记得多少次看到团队删除完全被遗忘的整个表格了。

删除（或归档）数据远比说起来容易，接下来的部分将解决这一挑战。

# 删除或归档数据

我希望本章能让您渴望删除或归档数据。太多的数据已经让我从太多愉快的梦中醒来：就好像 MySQL 有自己的思想，等到凌晨 3 点再填满磁盘。我曾经在三个不同的时区（因世界各地的会议而改变了我的时区）被应用程序叫醒。但是关于我，够了，让我们谈谈如何在不对应用程序造成负面影响的情况下删除或归档数据。

为简洁起见，我仅指出删除数据，而不是删除*或归档*数据，因为挑战几乎完全在前者：删除数据。归档数据需要首先复制数据，然后删除数据。复制数据应使用非锁定的`SELECT`语句以避免影响应用程序，然后将复制的行写入应用程序无法访问的另一个表格或数据存储中。即使使用非锁定的`SELECT`语句，您也必须对复制过程进行速率限制，以避免增加超过 MySQL 和应用程序可处理的 QPS。 （从“QPS 越少越好”回顾，QPS 相对于应用程序而言，很难增加。）

## 工具

您将不得不编写自己的工具来删除或归档数据。很抱歉带来不好的消息，但这是事实。好消息是删除和归档数据并不难——与您的应用程序相比可能微不足道。*至关重要* 的部分是限制执行 SQL 语句的循环速率。绝对不要这样做：

```
for {
    rowsDeleted = execute(“DELETE FROM table LIMIT 1000000”)
    if rowsDeleted == 0 {
        break
    }
}
```

`LIMIT 1000000` 子句可能过大，而`for`循环在语句之间没有延迟。那段伪代码很可能导致应用程序停机。 *批处理大小* 是安全且有效的数据归档工具的关键。

## 批处理大小

首先，可能允许您跳过阅读本节直到需要时的快捷方式：如果行数少于 1,000 行（没有`BLOB`、`TEXT`或`JSON`列），并且 MySQL 负载不重，可以安全地*手动*以单个`DELETE`语句删除 1,000 行或更少。*手动*意味着逐个执行每个`DELETE`语句（依次执行），而不是并行执行。不要编写程序来执行`DELETE`语句。大多数人类对于 MySQL 来说太慢了，所以无论您多快，都不能手动执行足够快以过载 MySQL 的`DELETE`…`LIMIT 1000`语句。谨慎使用此快捷方式，并请另一位工程师审查任何手动删除操作。

###### 注意

本节描述的方法侧重于`DELETE`，但通常适用于`INSERT`和`UPDATE`。对于`INSERT`，批处理大小由插入的行数控制，而不是`LIMIT`子句。

您可以快速且安全地删除行的速率取决于 MySQL 和应用程序能够维持的批处理大小，而不影响查询响应时间或复制延迟。第七章详细介绍了复制延迟。*批处理大小*是每个`DELETE`语句删除的行数，由`LIMIT`子句控制，并在必要时通过简单的延迟进行限制。

批处理大小根据执行时间进行校准；500 毫秒是一个良好的起点。这意味着每个`DELETE`语句执行时间不应超过 500 毫秒。这对两个原因至关重要：

复制延迟

源 MySQL 实例上的执行时间会导致复制 MySQL 实例上的复制延迟。如果源上的`DELETE`语句执行时间为 500 毫秒，则在复制实例上执行时间也为 500 毫秒，这会导致 500 毫秒的复制延迟。您无法避免复制延迟，但必须尽量减少，因为复制延迟会导致数据丢失。（目前，我对复制的许多细节进行了概述，稍后在第七章中详细说明。）

限流

在某些情况下，可以安全地执行没有延迟的`DELETE`语句——没有限流——因为校准的批处理大小限制了查询执行时间，从而限制了每秒查询率（QPS）。一个执行时间为 500 毫秒的查询只能以串行方式执行 2 QPS。但这些不是普通的查询：它们是专门设计的，用于尽可能访问和写入（删除）尽可能多的行。没有限流，批量写入可能会干扰其他查询并影响应用程序。

在删除数据时，限流至关重要：始终在`DELETE`语句之间加入延迟，并监视复制延迟。^(2)

###### 提示

始终在批量操作中加入限流。

要将批处理大小校准为 500 毫秒执行时间（或您选择的任何执行时间），从批处理大小 1000（`LIMIT 1000`）和`DELETE`语句之间的 200 毫秒延迟开始：200 毫秒是一个长延迟，但在校准批处理大小后可以减少它。在监控复制延迟和 MySQL 稳定性的同时运行至少 10 分钟——不要让 MySQL 延迟或不稳定。（复制延迟和 MySQL 稳定性分别在第七章和第六章中讨论。）使用查询报告（参见“报告”）来检查`DELETE`语句的最大执行时间，或直接在您的数据存档工具中进行测量。如果最大执行时间远低于目标值——500 毫秒——那么将批处理大小加倍，并再次运行 10 分钟。不断加倍批处理大小——或进行较小的调整——直到最大执行时间稳定在目标值之下为止。完成后，记录校准的批处理大小和执行时间，因为删除旧数据应该是一个经常发生的事件。

要使用校准的批处理大小设置节流，请通过每次 10 分钟重复运行逐渐减少延迟的过程重复上述过程。根据 MySQL 和应用程序的情况，您可能会达到零（无节流）。一旦出现复制延迟或 MySQL 不稳定的首个迹象，请停止，并将延迟增加到以前没有引起任何问题的值。完成后，出于相同的原因记录延迟：删除旧数据应该是一个经常发生的事件。

在校准了批处理大小并设置了节流后，最终可以计算速率：每秒可以删除多少行而不影响查询响应时间：`批处理大小 * DELETE QPS`。（使用查询报告来检查`DELETE`语句的 QPS，或直接在您的数据存档工具中测量。）预期速率会在一天中变化。如果应用程序在工作时间非常繁忙，唯一可持续的速率可能是零。如果你是一个雄心勃勃、一路高飞的人，醒来时数据库安静时可以尝试更高的速率：更大的批处理大小、更低的延迟或两者兼而有之。只需记住，在太阳升起并且数据库负载增加之前重新设置批处理大小和延迟。

###### 警告

MySQL 备份几乎总是在深夜运行。即使应用程序在深夜非常安静，数据库可能也很忙。

## 行锁争用

对于写入密集的工作负载，批量操作可能导致增加的*行锁竞争*：查询等待获取同一行（或附近行）的行锁。这个问题主要影响`INSERT`和`UPDATE`语句，但`DELETE`语句也可能受到影响，特别是如果删除的行与保留的行交错。问题在于批处理大小太大，即使在校准时间内执行也是如此。例如，MySQL 可能能够在 500 毫秒内删除 100,000 行，但如果这些行的锁与应用程序正在更新的行重叠，那么就会引起行锁竞争。

解决方案是通过校准更小的执行时间来减少批处理大小 —— 例如 100 毫秒。在极端情况下，您可能需要增加延迟：小批处理大小，长延迟。这样可以减少行锁竞争，对应用程序有利，但会使数据归档变慢。对于这种极端情况，没有神奇的解决方案；最好避免使用*更少的数据*和*更少的 QPS*。

## 空间与时间

删除数据并不会释放磁盘空间。行删除是逻辑操作，而非物理操作，在许多数据库中是一种常见的性能优化。当你删除 500 GB 的数据时，并不会获得 500 GB 的磁盘空间，而是获得 500 GB 的空闲页。内部细节更为复杂，超出了本书的范围，但总体概念是正确的：删除数据会释放空闲页，而非空闲磁盘空间。

空闲页不会影响性能，当插入新行时，InnoDB 会重用空闲页。如果删除的行将很快被新行替换，并且磁盘空间不受限制，那么空闲页和未索取的磁盘空间就不是问题。但请注意您的同事：如果您的公司运行自己的硬件，并且为您的应用程序的 MySQL 与其他应用程序的 MySQL 共享磁盘空间，则不要浪费其他应用程序可以使用的磁盘空间。在云中，存储是需要花钱的，因此不要浪费钱：回收磁盘空间。

从 InnoDB 中回收磁盘空间的最佳方法是通过执行一个空操作 `ALTER TABLE`…`ENGINE=INNODB` 语句来重建表格。这是一个已解决的问题，有三个优秀的解决方案：

+   [pt-online-schema-change](https://oreil.ly/8EJph)

+   [`gh-ost`](https://oreil.ly/IsV83)

+   [`ALTER TABLE`…`ENGINE=INNODB`](https://oreil.ly/JhWdg)

每种解决方案工作方式不同，但它们有一个共同点：所有这些解决方案都能在生产环境中*在线*重建巨大的 InnoDB 表格，而不会影响应用程序。阅读每个文档以决定哪一个对您最合适。

###### 注意

使用 `ALTER TABLE`…`ENGINE=INNODB` 重新构建表格时，请将 … 替换为表名。不要进行其他更改。

删除大量数据需要时间。您可能会读到或听到 MySQL 写入数据有多快，但那通常是基准测试的结果（参见“MySQL 调整”）。在实验室研究的光辉世界中，当然：MySQL 会利用您能提供的每一个时钟周期和磁盘 IOP。但在您和我经历的日常世界中，必须谨慎地删除数据，以避免对应用程序造成影响。坦率地说：这将比您想象的要花费更多时间。好消息是：如果操作正确执行——如“批量大小”中详细说明的那样——那么时间是站在您这边的。一个良好校准的、可持续的批量操作可以运行数天甚至数周。这包括您用于从 InnoDB 回收磁盘空间的解决方案，因为重建表格只是另一种批量操作。删除行需要时间，而回收磁盘空间还需要额外的时间。

## 二进制日志悖论

删除数据会生成数据。这种悖论发生在数据更改被写入二进制日志的情况下。虽然可以禁用二进制日志记录，但生产中从不这样做，因为二进制日志对于复制是必需的，而没有理智的生产系统会在没有副本的情况下运行。

如果表中包含大量的`BLOB`、`TEXT`或`JSON`列，则由于 MySQL 系统变量[`binlog_row_image`](https://oreil.ly/0bNcG)默认为`full`，二进制日志的大小可能会显著增加。该变量决定了如何将行图像写入二进制日志；它有三个设置：

`full`

写入每一列的值（完整行）。

`minimal`

写入已更改的列的值以及用于识别行的列。

`noblob`

写入除了不需要的`BLOB`和`TEXT`列之外的每一列的值。

如果没有依赖于二进制日志中完整行图像的外部服务（例如将更改流式传输到数据湖或大数据存储的数据流水线服务），那么使用`minimal`（或`noblob`）是安全且推荐的。

如果您使用[pt-online-schema-change](https://oreil.ly/2EB4l)或[`gh-ost`](https://oreil.ly/nUuvv)来重建表格，这些工具会复制表格（安全且自动），并且该复制过程会将更多数据更改写入二进制日志。然而，`ALTER TABLE`…`ENGINE=INNODB`默认为原地更改，不会复制表格。

###### 警告

删除大量数据时，由于二进制日志记录和删除数据并不释放磁盘空间，磁盘使用量会*增加*。

其矛盾之处在于，您必须确保服务器有足够的空闲磁盘空间来删除数据并重建表格。

# 总结

本章探讨了与性能相关的数据，并提出减少数据访问和存储是一种提高性能的技术——一种间接查询优化。主要的要点是：

+   较少的数据产生更好的性能。

+   较少的 QPS 更好，因为它是一种负担，而非资产。

+   索引对于最大化 MySQL 性能是必要的，但在某些情况下，索引可能无法帮助。

+   最小数据原则意味着：仅存储和访问所需的数据。

+   确保查询尽可能少地访问行。

+   不要存储比所需更多的数据：数据对你来说很有价值，但对 MySQL 而言只是多余的负担。

+   删除或归档数据非常重要，并且可以提高性能。

下一章将集中讨论访问模式，确定如何更改应用程序以有效使用 MySQL。

# 实践：审核查询数据访问

这一实践的目标是审核查询，以提高数据访问效率。这是高效数据访问检查表（表 3-2）：

+   ☐ 仅返回所需列

+   ☐ 减少查询复杂性

+   ☐ 限制行访问

+   ☐ 限制结果集

+   ☐ 避免对行进行排序

将检查表应用于前 10 个慢查询。（要获取慢查询，请参考“查询概要”和“实践：识别慢查询”。）修复一个简单的方法是任何`SELECT *`：显式选择所需的列。还要特别注意带有`ORDER BY`子句的查询：是否使用索引？是否有`LIMIT`？应用程序是否可以对行进行排序？

与“实践：识别慢查询”和“实践：查找重复索引”不同，没有工具来审核查询数据访问。但检查表只有五项，因此手动审核查询不会花费太多时间。仔细和有条不紊地审核查询，以实现最佳数据访问是专家级别的 MySQL 性能实践。

^(1) MySQL 不支持稀疏或部分索引。

^(2) 查看 GitHub Engineering 的[`freno`](https://oreil.ly/vSmUb)：一个用于 MySQL 的开源限流工具。
